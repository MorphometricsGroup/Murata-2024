{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8105037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pathlib\n",
    "import time\n",
    "import importlib\n",
    "import joblib\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.linalg import null_space\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43ec42ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import itertools\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "943173cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "if not os.path.abspath(\"../\") in sys.path:\n",
    "    sys.path.append(os.path.abspath(\"../\"))\n",
    "    sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "from src import normalization\n",
    "from src import Camera, metashape_Camera\n",
    "from src import camera_correspondence, FF_mat, epipole_angle, pair_and_key_gen, coll_dict_gen, pair_pt_gen\n",
    "from src import FR_check, coordinate_dict_gen\n",
    "from src import min_dist, tri, TDlines_gen, reprojection_gen, gen_support_dict, gen_support\n",
    "from src import all_D, frag_list_fraged, all_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dc183e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support_th(temp_folder, sup_th):\n",
    "    curve_fragment = []\n",
    "    for tag in tags:\n",
    "        if tag[1] == \"R\":\n",
    "            continue\n",
    "\n",
    "        with open(os.path.join(temp_folder, \"{0}_{1}_{2}.TDlines\".format(tag[0][0],tag[0][1],tag[1])), 'rb') as f:\n",
    "            lines_list = pickle.load(f)\n",
    "        #lines_list = TDlines[tag]\n",
    "\n",
    "        with open(os.path.join(temp_folder, \"{0}_{1}_{2}.support_dict\".format(tag[0][0],tag[0][1],tag[1])), 'rb') as f:\n",
    "            support_list, support_ac = pickle.load(f)\n",
    "        #support_list, support_ac = support_dict[tag][0], support_dict[tag][1]\n",
    "        tag_list = []\n",
    "        for col, sup_col, ac_col in zip(lines_list, support_list, support_ac):\n",
    "            col_curve_fragment = []\n",
    "            for frag, sup, sup_ac in zip(col, sup_col, ac_col):\n",
    "                if sup > sup_th:\n",
    "                    frag = np.reshape(frag,(-1, 3))\n",
    "                    frag = np.array([i for i,j in zip(frag, sup_ac >sup_th) if j])\n",
    "                    col_curve_fragment.append(frag)\n",
    "            tag_list.append(col_curve_fragment)\n",
    "        curve_fragment.append(tag_list)\n",
    "    return curve_fragment\n",
    "\n",
    "def rotation_mat(angle):\n",
    "    Rx = np.array([[1,0,0],\n",
    "                 [0, np.cos(angle[0]), -np.sin(angle[0])],\n",
    "                 [0, np.sin(angle[0]), np.cos(angle[0])]])\n",
    "\n",
    "    Ry = np.array([[np.cos(angle[1]), 0, np.sin(angle[1])],\n",
    "                 [0,1,0],\n",
    "                 [-np.sin(angle[1]), 0, np.cos(angle[1])]])\n",
    "\n",
    "    Rz = np.array([[np.cos(angle[2]), -np.sin(angle[2]), 0],\n",
    "                 [np.sin(angle[2]), np.cos(angle[2]), 0],\n",
    "                 [0,0,1]])\n",
    "    return Rz@Rx@Ry\n",
    "\n",
    "angle = [0, np.pi/2, np.pi/2] # pcd.rotate()\n",
    "angle = [-np.pi/2, np.pi/2, np.pi/2]\n",
    "R = rotation_mat(angle)\n",
    "R_mirror = np.array([[-1,0,0],\n",
    "                    [0,1,0],\n",
    "                    [0,0,1]])\n",
    "\n",
    "\n",
    "def curve_fragment_align(curve_fragment):\n",
    "    cfs = [[] for i in range(8)]\n",
    "    for cols in curve_fragment:\n",
    "        for i in range(len(cols)):\n",
    "            cfs[i] += cols[i]\n",
    "    cfs = [list(map(lambda x: x*10@R@R_mirror, cf_label)) for cf_label in cfs]\n",
    "    \n",
    "    return cfs\n",
    "\n",
    "def get_pts(mesh, edges, max_point_num=1000):\n",
    "    vertices = np.asarray(mesh.vertices)\n",
    "    edges = np.asarray(edges)\n",
    "    dist = 0\n",
    "    for i in range(len(vertices[edges])):\n",
    "        start = vertices[edges][i][0]\n",
    "        end = vertices[edges][i][1]\n",
    "        dist_part = np.sqrt(np.sum(np.square(start - end)))\n",
    "        dist += dist_part\n",
    "    unit_dist = dist/max_point_num\n",
    "    next_start_length = 0\n",
    "    next_start_partation = 0\n",
    "    pts_list = []\n",
    "    for i in range(len(vertices[edges])):\n",
    "        start = vertices[edges][i][0]\n",
    "        end = vertices[edges][i][1]\n",
    "        next_st_pt = start + (end - start)*next_start_partation\n",
    "        dist_part = np.sqrt(np.sum(np.square(start - end)))\n",
    "        dist_nx = np.sqrt(np.sum(np.square(next_st_pt - end)))\n",
    "        pts_num = int(dist_nx/unit_dist)+1\n",
    "        pts = next_st_pt + np.repeat(np.arange(pts_num),3).reshape((pts_num,3)) * (end - next_st_pt)/(pts_num-1)\n",
    "        end_pts = pts[-1]\n",
    "        next_start_length = pts_num*unit_dist - dist_part + next_start_length\n",
    "        next_start_partation = next_start_length/dist_part\n",
    "        pts_list.append(pts)\n",
    "\n",
    "    pts_array = np.concatenate(pts_list)\n",
    "\n",
    "    return pts_array\n",
    "\n",
    "def mesh_contours_load(individual):\n",
    "    mesh = o3d.io.read_triangle_mesh(\"postprocessing/polygon/quan_e_a/{}.ply\".format(individual))\n",
    "    edge_pts=[]\n",
    "    for i in range(np.max(np.asarray(mesh.cluster_connected_triangles()[0]))+1):\n",
    "        mesh = o3d.io.read_triangle_mesh(\"postprocessing/polygon/quan_e_a/{}.ply\".format(individual))\n",
    "        mesh.triangles = o3d.utility.Vector3iVector(np.asarray(mesh.triangles)[np.asarray(mesh.cluster_connected_triangles()[0])==i])\n",
    "        #_, _, area = mesh.cluster_connected_triangles()\n",
    "        edges = mesh.get_non_manifold_edges(allow_boundary_edges=False)\n",
    "        pts_array = get_pts(mesh, edges)\n",
    "        edge_pts.append(pts_array)\n",
    "    edge_pts[5], edge_pts[6], edge_pts[7] = edge_pts[6], edge_pts[7], edge_pts[5]\n",
    "    return edge_pts\n",
    "\n",
    "def cf_evaluation_core(edge_pts_label, cfs_label, t_dist=0.1, t_part=0.5):\n",
    "    rec_TF_list = []\n",
    "    for i, cf in enumerate(cfs_label):\n",
    "        edge_pt_bro = np.repeat(edge_pts_label, len(cf), axis=0).reshape(edge_pts_label.shape[0], len(cf), edge_pts_label.shape[1])\n",
    "        all_dist = np.sqrt(np.sum(np.square(cf - edge_pt_bro), axis=2))\n",
    "        min_dist_idx_rec = np.argmin(all_dist.T, axis=1)\n",
    "        min_dist_idx_pre = np.argmin(all_dist, axis=1)\n",
    "        if i == 0:\n",
    "            temp_dist_pre = np.ones(min_dist_idx_pre.shape)*1000\n",
    "        min_dist_rec = all_dist.T[np.arange(len(all_dist.T)), min_dist_idx_rec]\n",
    "        min_dist_pre = all_dist[np.arange(len(all_dist)), min_dist_idx_pre]\n",
    "        rec_TF = (np.sum(min_dist_rec<t_dist)/len(min_dist_rec))>t_part\n",
    "        rec_TF_list.append(rec_TF)\n",
    "        temp_dist_pre[np.where(temp_dist_pre>min_dist_pre)[0]] = min_dist_pre[np.where(temp_dist_pre>min_dist_pre)[0]]\n",
    "    recall = sum(rec_TF_list)/len(rec_TF_list)\n",
    "    precision = np.sum(temp_dist_pre<t_dist)/len(temp_dist_pre)\n",
    "    return precision, recall\n",
    "\n",
    "def cf_evaluation(edge_pts, cfs):\n",
    "    leaves_precision = []\n",
    "    leaves_recall = []\n",
    "    for edge_pts_label, cfs_label in zip(edge_pts, cfs):\n",
    "        precision, recall = np.nan, np.nan\n",
    "        if len(cfs_label) != 0:\n",
    "            precision, recall = cf_evaluation_core(edge_pts_label, cfs_label)\n",
    "    leaves_precision.append(precision)\n",
    "    leaves_recall.append(recall)\n",
    "    return leaves_precision, leaves_recall\n",
    "\n",
    "def evaluation(individual, img_num, temp_folder):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    edge_pts = mesh_contours_load(individual)\n",
    "    for sup_th in range(img_num+1):\n",
    "        curve_fragment = support_th(temp_folder, sup_th)\n",
    "        cfs = curve_fragment_align(curve_fragment)\n",
    "        precision, recall = cf_evaluation(edge_pts, cfs)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "    return precision_list, recall_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cc92b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num = 128\n",
    "individual = \"q_1_a\"\n",
    "temp_folder = \"temp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7ae3ac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_list = [Camera(i) for i in range(img_num)]\n",
    "for i in range(len(cam_list)):\n",
    "    cam_list[i].img_load(\"images/quan_equidistant/{}/{}\".format(individual, str(img_num)))\n",
    "    cam_list[i].contour_extraction()\n",
    "    cam_list[i].label_load(\"preprocessing/labels/q_e_l_noise_3mm/{}/{}_{}_label.pickle\".format(individual, individual, str(img_num)))\n",
    "    cam_list[i].correspondence_contour()\n",
    "    cam_list[i].para_load(\"view_mats/q_e_noise_3mm/view_mat_{}/{}.csv\".format(str(img_num), str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3ec18a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "w = 5\n",
    "for cnum in range(len(cam_list)):\n",
    "    sparse_mats_list = []\n",
    "    for j in range(len(cam_list[cnum].contour_list)):\n",
    "        new_img = np.zeros((cam_list[0].img[0].shape[0],cam_list[0].img[0].shape[1]),dtype=np.uint8)\n",
    "        for i in range(len(cam_list[cnum].contour_list[j])):\n",
    "            curve = cam_list[cnum].contour_list[j][i][~np.isnan(cam_list[cnum].contour_list[j][i])].reshape((-1,2)).astype(int)\n",
    "            new_img[curve[:,1],curve[:,0]]=True\n",
    "        dilation = cv2.dilate(new_img, kernel, iterations = w)\n",
    "        new_img = csr_matrix(dilation, dtype=np.uint8)\n",
    "        sparse_mats_list.append(new_img)\n",
    "    cam_list[cnum].contour_img = sparse_mats_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5fee65c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_path = pathlib.Path(temp_folder)\n",
    "tags_path = list(temp_path.glob(\"*.TDlines\"))\n",
    "\n",
    "tags = []\n",
    "for tag_path in tags_path:\n",
    "    tag_sp = tag_path.stem.split(\"_\")\n",
    "    tag_arr = ((int(tag_sp[0]), int(tag_sp[1])), tag_sp[2])\n",
    "    tags.append(tag_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123cbabd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
