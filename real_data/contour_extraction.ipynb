{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pathlib\n",
    "import os\n",
    "from scipy.linalg import null_space\n",
    "import sympy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "class Camera:\n",
    "    \n",
    "    def __init__(self, val):\n",
    "        self.img_num = val # カメラ番号（int;コンストラクタ）\n",
    "        \n",
    "        f = 8000/3\n",
    "        cx = 1920/2\n",
    "        cy = 1080/2\n",
    "        A = np.zeros((3,3))\n",
    "        A[0,0] = f\n",
    "        A[0,2] = cx\n",
    "        A[1,1] = f\n",
    "        A[1,2] = cy\n",
    "        A[2,2] = 1\n",
    "        \n",
    "        self.A = A # 内部パラメータ(ndarray)後から更新\n",
    "\n",
    "    def img_load(self):\n",
    "        folder_path = \"images/one_hole_bird\"\n",
    "        file_path = os.path.join(folder_path, str(self.img_num) + \".png\")\n",
    "        img = cv2.imread(file_path, 1)# BGRで読み込み\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.flip(img, 1)\n",
    "        self.img = img # 画像(ndarray)\n",
    "        \n",
    "    def contour_extraction(self):\n",
    "        \n",
    "        color_arr = np.array([[255,0,0],[0,255,0],[0,0,255],\n",
    "                             [255,255,0],[255,0,255],[0,255,255],\n",
    "                             [127,127,127],[127,0,127],[0,127,127]],dtype = np.int16)\n",
    "        masks = np.ones((self.img.shape[0], self.img.shape[1], 9), dtype=np.uint8)\n",
    "        \n",
    "        for i, color in enumerate(color_arr):\n",
    "            lower = np.clip(color, 0, 255)\n",
    "            upper = np.clip(color, 0, 255)\n",
    "            img_mask = cv2.inRange(self.img, lower, upper)\n",
    "            masks[:,:,i] = img_mask\n",
    "        \n",
    "        #self.masks = masks # 色ごとのマスク(nd.array)\n",
    "        \n",
    "        contour_list = []\n",
    "\n",
    "        # 色ごとに輪郭（閉曲線）を抽出\n",
    "        for i in range(masks.shape[2]):\n",
    "            contours, hierarchy = cv2.findContours(masks[:,:,i],cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "            contour_list.append(contours)\n",
    "        self.contour_list = contour_list # 輪郭のリスト(list,ndarray)\n",
    "\n",
    "        #self.frag_list = contours2fragments(self.contour_list) # フラグメントのリスト(list,ndarray)\n",
    "\n",
    "    def para_load(self):\n",
    "\n",
    "        folder_path = pathlib.Path(\"view_mats/view_mat_bird\")\n",
    "        file_path = os.path.join(folder_path, str(self.img_num)+\".csv\")\n",
    "        self.Rt = np.loadtxt(file_path, delimiter=\"\\t\")\n",
    "        self.P = np.dot(self.A, self.Rt[0:3,0:4])\n",
    "        self.cam_world_cood = -np.dot(self.Rt[0:3,0:3].T, self.Rt[0:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "class metashape_Camera:\n",
    "    def __init__(self, val):\n",
    "        self.img_num = val\n",
    "        inner_para_path = pathlib.Path(\"view_mat/inner_para.csv\")\n",
    "        self.A = np.loadtxt(str(inner_para_path), delimiter=\",\")\n",
    "\n",
    "    def img_load(self):\n",
    "        folder_path = \"GmJMC025_02\"\n",
    "        file_path = os.path.join(folder_path, str(self.img_num) + \".JPG\")\n",
    "        img = cv2.imread(file_path, 1)# BGRで読み込み\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #img = cv2.flip(img, 1) # 反転 unity用?\n",
    "        self.img = img # 画像(ndarray)\n",
    "        self.img_shape = img.shape\n",
    "\n",
    "    def contour_load(self):\n",
    "        folder = pathlib.Path(\"GmJMC025_02_mask\")\n",
    "        masks_path = folder.glob(str(self.img_num)+\"_\"+\"*\"+\".csv\")\n",
    "\n",
    "        #mask_list = []\n",
    "        contour_list = []\n",
    "        for mask_path in masks_path:\n",
    "            mask = cood_to_mask(mask_path, (self.img_shape[0], self.img_shape[1]))\n",
    "            contours, hierarchy = cv2.findContours(mask,cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "            #mask_list.append(mask)\n",
    "            contour_list.append(contours)\n",
    "        #self.masks = np.asarray(mask_list).transpose(1, 2, 0)\n",
    "        self.contour_list = contour_list\n",
    "        \n",
    "    def label_load(self):\n",
    "        with open('label.pickle', 'rb') as f:\n",
    "            self.labels = pickle.load(f)\n",
    "        \n",
    "        max_num = 0\n",
    "        for l in self.labels:\n",
    "            temp_max = np.max(l)\n",
    "            if max_num < temp_max:\n",
    "                max_num = temp_max\n",
    "        self.max_num = max_num\n",
    "        \n",
    "    def correspondence_contour(self):\n",
    "        correspondence_list = []\n",
    "\n",
    "        for i in range(self.max_num+1):\n",
    "            temp_c_list = []\n",
    "            idx = np.where(self.labels[self.img_num] == i)\n",
    "            if idx[0].size != 0:\n",
    "                for j in idx[0]:\n",
    "                    temp_c_list += self.contour_list[j]\n",
    "            correspondence_list.append(temp_c_list)\n",
    "        self.contour_list = correspondence_list\n",
    "\n",
    "    def para_load(self):\n",
    "        folder_path = pathlib.Path(\"view_mat\")\n",
    "        file_path = os.path.join(folder_path, str(self.img_num)+\".csv\")\n",
    "        self.Rt = np.loadtxt(file_path, delimiter=\",\")\n",
    "        self.Rt = np.linalg.pinv(self.Rt)\n",
    "        self.P = np.dot(self.A, self.Rt[0:3,0:4])\n",
    "        self.cam_world_cood = -np.dot(self.Rt[0:3,0:3].T, self.Rt[0:3,3])\n",
    "        \n",
    "def cood_to_mask(csv_path, im_shape):\n",
    "    idx = np.loadtxt(str(csv_path), delimiter=\",\")\n",
    "    idx = idx.astype(np.int64)\n",
    "    \n",
    "    mask = np.zeros(im_shape, dtype=np.uint8)\n",
    "    \n",
    "    if idx.size == 0:\n",
    "        return mask\n",
    "    \n",
    "    mask[idx[0],idx[1]] = 255\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correspondence_contour(self):\n",
    "    correspondence_list = []\n",
    "\n",
    "    for i in range(max_num+1):\n",
    "        temp_c_list = []\n",
    "        idx = np.where(labels[self.img_num] == 1)\n",
    "        if idx[0].size != 0:\n",
    "            for j in idx[0]:\n",
    "                temp_c_list.append(self.contour_list[j])\n",
    "        correspondence_list.append(temp_c_list)\n",
    "    self.correspondence_list = correspondence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 曲線分割\n",
    "def split_list(contour_length, max_frag_len=100, min_frag_len=40, min_overrap=10):\n",
    "    \n",
    "    # 輪郭のフラグメントの位置を指定(最小40 pixl)\n",
    "    if contour_length > max_frag_len:\n",
    "        pass\n",
    "    \n",
    "    elif contour_length < min_frag_len:\n",
    "        return None\n",
    "    \n",
    "    elif contour_length == min_frag_len:\n",
    "        return [[0,min_frag_len-1]]\n",
    "    \n",
    "    else:\n",
    "        max_frag_len = contour_length\n",
    "    \n",
    "    step0 = np.random.randint(min_frag_len, max_frag_len) # 一つ目のフラグメントの長さ（40から100）\n",
    "    sep_list = [[0,step0]]\n",
    "    back = np.random.randint(min_overrap, step0-1) # フラグメントを重ねるために戻す分を決める（最小10 pixl）\n",
    "    next_start = step0 - back\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # 戻った分(back)より進む\n",
    "        if back+1 > min_frag_len:\n",
    "            step = np.random.randint(back+1, max_frag_len)\n",
    "        else:\n",
    "            step = np.random.randint(min_frag_len, max_frag_len)\n",
    "\n",
    "        full_length = next_start + step\n",
    "        sept = [next_start, full_length]\n",
    "        sep_list.append(sept)\n",
    "        back = np.random.randint(min_overrap, step-1)\n",
    "        next_start = full_length - back\n",
    "\n",
    "        # 終了判定\n",
    "        if full_length > contour_length:\n",
    "            break\n",
    "    \n",
    "    # 超過した分戻す（長さはそのまま）\n",
    "    difference = sep_list[-1][1] - (contour_length-1)\n",
    "    sep_list[-1][0] -= difference\n",
    "    sep_list[-1][1] -= difference\n",
    "    \n",
    "    return sep_list\n",
    "\n",
    "\n",
    "def contours_split(contour):\n",
    "    \n",
    "    #contour.shape == (N, 2)\n",
    "    contour_length = contour.shape[0]\n",
    "    sp_list = split_list(contour_length)\n",
    "    \n",
    "    if sp_list == None:\n",
    "        return None\n",
    "    \n",
    "    frag_list = []\n",
    "    # 位置のリスト通りにスライス\n",
    "    for sp in sp_list:\n",
    "        #print(sp)\n",
    "        frag_list.append(contour[sp[0]:sp[1],:])\n",
    "\n",
    "    return frag_list\n",
    "\n",
    "\n",
    "def all_fraged(contours_list):\n",
    "    \n",
    "    # 輪郭のリストからフラグメントのリストを得る\n",
    "    frags_list = []\n",
    "\n",
    "    #for i in contours_list:\n",
    "    #temp_list = []\n",
    "    frags = []\n",
    "    for j in contours_list:\n",
    "        temp_frags = contours_split(j.squeeze())\n",
    "            \n",
    "        if temp_frags != None:\n",
    "            frags += temp_frags\n",
    "\n",
    "    #if frags != []:\n",
    "    #    frags_list.append(frags)\n",
    "    \n",
    "    return frags\n",
    "\n",
    "def frag_list_fraged(frags_list):# frags_list[色][輪郭][sep][座標]\n",
    "    img_frag_list = []\n",
    "    for frag in frags_list:\n",
    "        color_frag = all_fraged(frag)\n",
    "        img_frag_list.append(color_frag)\n",
    "    return img_frag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera対応\n",
    "def cam_pos_mean(cam_list):\n",
    "    _cam_pos = np.zeros(3)\n",
    "    for cam in cam_list:\n",
    "        _cam_pos += cam.cam_world_cood\n",
    "    cam_mean = _cam_pos/len(cam_list)\n",
    "    return cam_mean\n",
    "\n",
    "def vec_L2(vec):\n",
    "    return np.sum(vec**2)**(1/2)\n",
    "\n",
    "def cal_angle(cam_pos1, cam_pos2, cam_mean):\n",
    "    vec1 = cam_pos1-cam_mean\n",
    "    vec2 = cam_pos2-cam_mean\n",
    "    cossin = np.dot(vec1, vec2)/(vec_L2(vec1)*vec_L2(vec2))\n",
    "    angle = np.arccos(cossin)\n",
    "    return angle\n",
    "\n",
    "def cal_angle_all(cam_list):\n",
    "    pair_list = []\n",
    "    cam_mean = cam_pos_mean(cam_list)\n",
    "    for i, cam1 in enumerate(cam_list):\n",
    "        for j, cam2 in enumerate(cam_list):\n",
    "            if i == j or i > j:\n",
    "                continue\n",
    "            cam1_pos = cam1.cam_world_cood\n",
    "            cam2_pos = cam2.cam_world_cood\n",
    "            angle = cal_angle(cam1_pos, cam2_pos, cam_mean)\n",
    "            if angle < 1/9*np.pi:\n",
    "                pair_list.append((i,j))\n",
    "    return pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epipole取得\n",
    "\n",
    "def SS_mat(vec3):\n",
    "    vec3 = np.squeeze(vec3)\n",
    "    SS_mat = np.zeros((3, 3))\n",
    "    SS_mat[0,1] = -vec3[2]\n",
    "    SS_mat[0,2] = vec3[1]\n",
    "    SS_mat[1,0] = vec3[2]\n",
    "    SS_mat[1,2] = -vec3[0]\n",
    "    SS_mat[2,0] = -vec3[1]\n",
    "    SS_mat[2,1] = vec3[0]\n",
    "    return SS_mat\n",
    "\n",
    "def FF_mat(A1, A2, Rt1, Rt2):\n",
    "    P1 = np.dot(A1, Rt1[0:3,0:4])\n",
    "    P2 = np.dot(A2, Rt2[0:3,0:4])\n",
    "    cam_pos1 = -np.dot(Rt1[0:3,0:3].T, Rt1[0:3,3])\n",
    "    cam_pos1 = np.array([cam_pos1[0], cam_pos1[1], cam_pos1[2], 1])\n",
    "    epipole2 = np.dot(P2, cam_pos1)\n",
    "    cam_pos2 = -np.dot(Rt2[0:3,0:3].T, Rt2[0:3,3])\n",
    "    cam_pos2 = np.array([cam_pos2[0], cam_pos2[1], cam_pos2[2], 1])\n",
    "    epipole1 = np.dot(P1, cam_pos2)\n",
    "    return epipole1, epipole2, np.dot(SS_mat(epipole2), np.dot(P2, np.linalg.pinv(P1)))\n",
    "\n",
    "def contour_disassembly(contour_list):\n",
    "    con_dis = []\n",
    "    for i in range(len(contour_list)):\n",
    "        if contour_list[i] == []:\n",
    "            continue\n",
    "        which_dis = np.concatenate(contour_list[i])\n",
    "        con_dis.append(which_dis)\n",
    "        \n",
    "    return np.concatenate(con_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポーラ関係\n",
    "def epilines_para(frags, F):\n",
    "    \n",
    "    lines_list = []\n",
    "    for color in frags:\n",
    "        temp_color_list = []\n",
    "        for frag in color:\n",
    "            frag_lines = cv2.computeCorrespondEpilines(frag.reshape(-1,1,2), 1,F) # ndarray(フラグメントの座標数,1,3)\n",
    "            temp_color_list.append(frag_lines)\n",
    "\n",
    "        lines_list.append(temp_color_list)\n",
    "    \n",
    "    return lines_list\n",
    "\n",
    "\n",
    "def para2line(parameter):\n",
    "    \n",
    "    # 一つのパラメータが渡された時を想定\n",
    "    line_coode = np.zeros((1920,2), dtype=np.int64)\n",
    "    para = np.squeeze(parameter)# 3次ベクトル\n",
    "    for x in range(1920):\n",
    "        y = int((-para[0]*x - para[2])/para[1])\n",
    "        line_coode[x,0] = x\n",
    "        line_coode[x,1] = y\n",
    "    \n",
    "    return line_coode\n",
    "\n",
    "\n",
    "def epiline_cal(frag_paras):\n",
    "    # 全ての色に対するエピポーラ線の帯の計算\n",
    "    # lines[色][フラグメント][線][座標]\n",
    "    lines = []\n",
    "    for color in frag_paras:\n",
    "        temp_color = []\n",
    "        \n",
    "        for frag in color:\n",
    "            temp_line = []\n",
    "\n",
    "            for point in frag:\n",
    "                line = para2line(point)\n",
    "                temp_line.append(line)\n",
    "\n",
    "            temp_color.append(temp_line)\n",
    "        lines.append(temp_color)\n",
    "        \n",
    "    return lines\n",
    "\n",
    "\n",
    "def frags_vs_line(img2_frags, frag_epiline):\n",
    "    \n",
    "    # frag_epiline shape(1920, 2)\n",
    "    surport = np.zeros(len(img2_frags))\n",
    "    for i in frag_epiline:\n",
    "        for j, frag in enumerate(img2_frags):\n",
    "            if i in frag:\n",
    "                surport[j] += 1\n",
    "    \n",
    "    return surport\n",
    "\n",
    "\n",
    "def pair_frag_idx(img2_frags, frag_epilines):\n",
    "    surport = np.zeros(len(img2_frags))\n",
    "    for epi in frag_epilines:\n",
    "        surport += frags_vs_line(img2_frags, epi)\n",
    "        \n",
    "    return surport, np.argmax(surport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(vec3):\n",
    "    return vec3[0]/vec3[2], vec3[1]/vec3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構築\n",
    "def nom_F(F):\n",
    "    return (1/sum(sum(F**2))**(1/2))*F\n",
    "\n",
    "def cover_mat(x1, y1, x2, y2):\n",
    "    return np.array([[x1**2+x2**2, x2*y2, x2, x1*y1, 0, 0, x1, 0, 0],\n",
    "                    [x2*y2, x1**2+y2**2, y2, 0, x1*y1, 0, 0, x1, 0],\n",
    "                    [x2, y2, 1, 0, 0, 0, 0, 0, 0],\n",
    "                    [x1*y1, 0, 0, y1**2+x2**2, x2*y2, x2, y1, 0, 0],\n",
    "                    [0, x1*y1, 0, x2*y2, y1**2+y2**2, y2, 0, y1, 0],\n",
    "                    [0, 0, 0, x2, y2, 1, 0, 0, 0],\n",
    "                    [x1, 0, 0, y1, 0, 0, 1, 0, 0],\n",
    "                    [0, x1, 0, 0, y1, 0, 0, 1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "def min_dist(F, pt1, pt2):# pt1が画像2上の点，pt2が画像1上の点\n",
    "    S0 = 10**10\n",
    "    x1_ori = pt1[0]\n",
    "    y1_ori = pt1[1]\n",
    "    x2_ori = pt2[0]\n",
    "    y2_ori = pt2[1]\n",
    "    \n",
    "    x1 = pt1[0]\n",
    "    y1 = pt1[1]\n",
    "    x2 = pt2[0]\n",
    "    y2 = pt2[1]\n",
    "    \n",
    "    x1_tilda = 0\n",
    "    y1_tilda = 0\n",
    "    x2_tilda = 0\n",
    "    y2_tilda = 0\n",
    "    thita = nom_F(F).flatten()\n",
    "    it = 0\n",
    "    while True:\n",
    "        V_eps = cover_mat(x1, y1, x2, y2)\n",
    "        eps_ast = np.array([x1*x2 + x2*x1_tilda + x2*x2_tilda,\n",
    "                           x1*y2 + y2*x1_tilda + x2*y2_tilda,\n",
    "                           x1 + x1_tilda,\n",
    "                           y1*x2 + x2*y1_tilda + y1 * x2_tilda,\n",
    "                           y1* y2 + y2*y1_tilda + y1*y2_tilda,\n",
    "                           y1 + y1_tilda,\n",
    "                           x2 + x2_tilda,\n",
    "                           y2 + y2_tilda,\n",
    "                           1])\n",
    "        \n",
    "        x1_y1_tilda = np.dot(eps_ast, thita) * np.dot(np.array([[thita[0], thita[1], thita[2]], [thita[3], thita[4], thita[5]]]), np.array([x2, y2, 1])) / np.dot(thita, np.dot(V_eps, thita))\n",
    "        x2_y2_tilda = np.dot(eps_ast, thita) * np.dot(np.array([[thita[0], thita[3], thita[6]], [thita[1], thita[4], thita[7]]]), np.array([x1, y1, 1])) / np.dot(thita, np.dot(V_eps, thita))\n",
    "        \n",
    "        x1_tilda = x1_y1_tilda[0]\n",
    "        y1_tilda = x1_y1_tilda[1]\n",
    "        x2_tilda = x2_y2_tilda[0]\n",
    "        y2_tilda = x2_y2_tilda[1]\n",
    "        \n",
    "        x1 = x1_ori - x1_tilda\n",
    "        y1 = y1_ori - y1_tilda\n",
    "        x2 = x2_ori - x2_tilda\n",
    "        y2 = y2_ori - y2_tilda\n",
    "        \n",
    "        S = x1_tilda**2 + y1_tilda**2 + x2_tilda**2 + y2_tilda**2\n",
    "        \n",
    "        if abs(S0 - S) < 0.00001:\n",
    "            break\n",
    "\n",
    "        elif it == 20:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            S0 = S\n",
    "            it += 1\n",
    "\n",
    "    return np.array((x1, y1)), np.array((x2, y2))\n",
    "\n",
    "def Ps(P, pt):\n",
    "    a = P[0,0] - pt[0]*P[2,0]\n",
    "    b = P[0,1] - pt[0]*P[2,1]\n",
    "    c = P[0,2] - pt[0]*P[2,2]\n",
    "    d = P[0,3]\n",
    "    e = pt[0]*P[2,3]\n",
    "    f = P[1,0] - pt[1]*P[2,0]\n",
    "    g = P[1,1] - pt[1]*P[2,1]\n",
    "    h = P[1,2] - pt[1]*P[2,2]\n",
    "    i = P[1,3]\n",
    "    j = pt[1]*P[2,3]\n",
    "    return a, b, c, d, e, f, g, h, i, j\n",
    "\n",
    "def tri(P1, P2, pt1, pt2):\n",
    "    #x = sympy.Symbol('x')\n",
    "    #y = sympy.Symbol('y')\n",
    "    #z = sympy.Symbol('z')\n",
    "    a1, b1, c1, d1, e1, f1, g1, h1, i1, j1 = Ps(P1, pt1)\n",
    "    a2, b2, c2, d2, e2, f2, g2, h2, i2, j2 = Ps(P2, pt2)\n",
    "    T = np.array([[a1, b1, c1],\n",
    "                 [f1, g1, h1],\n",
    "                 [a2, b2, c2],\n",
    "                 [f2, g2, h2]])\n",
    "    p = np.array([[d1-e1],\n",
    "                 [i1-j1],\n",
    "                 [d2-e2],\n",
    "                 [i2-j2]])\n",
    "    T_inv = np.linalg.pinv(T)\n",
    "    result_pt = np.dot(T_inv, -p)\n",
    "    return result_pt\n",
    "\n",
    "    #expr1 = a1*x + b1*y + c1*z + d1 - e1\n",
    "    #expr2 = f1*x + g1*y + h1*z + i1 - j1\n",
    "    #expr3 = a2*x + b2*y + c2*z + d2 - e2\n",
    "    #expr4 = f2*x + g2*y + h2*z + i2 - j2\n",
    "    #print(expr1.subs(sympy.solve([expr2, expr3, expr4])))\n",
    "    #result = sympy.solve([expr2, expr3, expr4])\n",
    "    \n",
    "    #return np.array([result[x], result[y], result[z]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pt1 = [1920-741,758] # 0\n",
    "pt2 = [1920-858,834] # 2\n",
    "F = cam_pairs_F[(0,2)] #0to2\n",
    "pt2, pt1 = min_dist(F, pt2, pt1)\n",
    "print(pt1,pt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pt1 = np.array([pt1[0],pt1[1],1]) # 0\n",
    "pt2 = np.array([pt2[0],pt2[1],1]) # 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot(np.dot(pt2, F),pt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tri(cam_list[0].P, cam_list[2].P, pt1, pt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: loadtxt: Empty input file: \"GmJMC025_02_mask\\245_3.csv\"\n"
     ]
    }
   ],
   "source": [
    "cam_list = [metashape_Camera(i) for i in range(0,264)]\n",
    "for i in range(len(cam_list)):\n",
    "    cam_list[i].img_load()\n",
    "    cam_list[i].contour_load()\n",
    "    cam_list[i].label_load()\n",
    "    cam_list[i].correspondence_contour()\n",
    "    cam_list[i].para_load()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポール取得\n",
    "cam_pairs = cal_angle_all(cam_list)\n",
    "\n",
    "epipole_dict = {i:[] for i in range(len(cam_list))}\n",
    "cam_pairs_F = {}\n",
    "for i in cam_pairs:\n",
    "    epipole1, epipole2, F = FF_mat(cam_list[i[0]].A, cam_list[i[1]].A, cam_list[i[0]].Rt, cam_list[i[1]].Rt)\n",
    "    epipole_dict[i[0]].append(normalization(epipole1))\n",
    "    epipole_dict[i[1]].append(normalization(epipole2))\n",
    "    cam_pairs_F[i] = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エピポールと輪郭上の点を結んだ直線と，x軸のなす角\n",
    "def gene(angles):\n",
    "    # 正規化\n",
    "    B = list(map(lambda y:y-min(angles),angles))\n",
    "    return list(map(lambda y: (y-min(B))/(max(B)-min(B)), B))\n",
    "\n",
    "def epipole_angle(img_num, epipole_dict):\n",
    "    cam = cam_list[img_num]\n",
    "    angle_list = []\n",
    "    \n",
    "    for epi in epipole_dict[img_num]:\n",
    "        epi_angle_list = []\n",
    "        epi_x = epi[0]\n",
    "        epi_y = epi[1]\n",
    "        for color in cam.contour_list:\n",
    "            color_angle_list = []\n",
    "            for contour in color:\n",
    "                contour_angle_list= []\n",
    "                for cood in contour:\n",
    "                    x = cood[0][0]\n",
    "                    y = cood[0][1]\n",
    "                    tilt = (y-epi_y)/(x-epi_x)\n",
    "                    angle = np.arctan(tilt)\n",
    "                    contour_angle_list.append(angle)\n",
    "                contour_angle_list = gene(contour_angle_list)\n",
    "                color_angle_list.append(contour_angle_list)\n",
    "            epi_angle_list.append(color_angle_list)\n",
    "        angle_list.append(epi_angle_list)\n",
    "    return angle_list\n",
    "    \n",
    "def expand(idx_l, list_length):\n",
    "    del_list = []\n",
    "    for i in idx_l:\n",
    "        if np.isnan(i):\n",
    "            continue\n",
    "        if i-2 < 0:\n",
    "            del_list.append(list_length + i-2)\n",
    "        else:\n",
    "            del_list.append(i-2)\n",
    "        \n",
    "        if i-1 < 0:\n",
    "            del_list.append(list_length + i-1)\n",
    "        else:\n",
    "            del_list.append(i-1)\n",
    "        \n",
    "        del_list.append(i)\n",
    "        \n",
    "        if i+1 > list_length-1:\n",
    "            del_list.append(i+1-list_length)\n",
    "        else:\n",
    "            del_list.append(i+1)\n",
    "        if i+2 > list_length-1:\n",
    "            del_list.append(i+2-list_length)\n",
    "        else:\n",
    "            del_list.append(i+2)\n",
    "    return sorted(list(set(del_list)))\n",
    "\n",
    "def differential(angles):\n",
    "    # エピポーラ線に平行な接線をもつ点(前後方微分の正負を比べたほうが良い)\n",
    "    del_idx = []\n",
    "    for i in range(len(angles)):\n",
    "        if np.isnan(angles[i]):\n",
    "            continue\n",
    "        if i == len(angles)-1:\n",
    "            if np.sign(angles[i]-angles[i-1]) != np.sign(angles[0]-angles[i]): #or abs(angles[0]-angles[i-1])/2 < 0.001:\n",
    "                del_idx.append(i)\n",
    "        else:\n",
    "            if np.sign(angles[i]-angles[i-1]) != np.sign(angles[i+1]-angles[i]):# or abs(angles[i+1]-angles[i-1])/2 < 0.001:\n",
    "                del_idx.append(i)\n",
    "    #del_idx = expand(del_idx, len(angles))\n",
    "    \n",
    "    return del_idx\n",
    "\n",
    "\n",
    "def marge_del(epi_del_list):\n",
    "    ### 未検証\n",
    "    im_del_list = []\n",
    "    for a in range(len(epi_del_list[0])):\n",
    "        color_list = []\n",
    "        for b in range(len(epi_del_list[0][a])):\n",
    "            con_list = []\n",
    "            for i in range(len(epi_del_list)):\n",
    "                con_list += epi_del_list[i][a][b]\n",
    "            color_list.append(con_list)\n",
    "        im_del_list.append(color_list)\n",
    "    return im_del_list\n",
    "\n",
    "\n",
    "def all_D(angles_list):\n",
    "    # 画像1枚に対して削除リストを作成\n",
    "    all_del_list = []\n",
    "    if len(angles_list) == 0:\n",
    "        return all_del_list\n",
    "    for epi in angles_list:\n",
    "        epi_del_list = []\n",
    "        for color in epi:\n",
    "            color_del_list = []\n",
    "            for contour in color:\n",
    "                #if len(contour)<40:\n",
    "                #    continue\n",
    "                del_idx = differential(contour)\n",
    "                color_del_list.append(del_idx)\n",
    "            epi_del_list.append(color_del_list)\n",
    "        all_del_list.append(epi_del_list)\n",
    "    all_del_list = marge_del(all_del_list)\n",
    "    return all_del_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポーラ線との接線で分割\n",
    "def separate(contour, del_idx):\n",
    "    # 一つの輪郭に対し削除リストから削除\n",
    "    start = 0\n",
    "    newArray = []\n",
    "    for d in del_idx:\n",
    "        if contour[start:d] != []:\n",
    "            if contour[start:d].size != 0:\n",
    "                newArray.append(contour[start:d])\n",
    "        start = d+1\n",
    "\n",
    "    if contour[start:].size != 0:\n",
    "        newArray.append(contour[start:])\n",
    "    return newArray\n",
    "\n",
    "def all_sep(con_list, del_list):\n",
    "    n_list = []\n",
    "    for col, del_col in zip(con_list, del_list):\n",
    "        n_col_list = []\n",
    "        for con, del_con in zip(col, del_col) :\n",
    "            n_con = separate(con, del_con)\n",
    "            for frag in n_con:\n",
    "                n_col_list.append(frag)\n",
    "        n_list.append(n_col_list)\n",
    "    return n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  import sys\n",
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# フラグメントのリストを作る\n",
    "for i in range(len(cam_list)):\n",
    "    im_del_list = all_D(epipole_angle(i, epipole_dict))# im_del_list[color][contour][del_idx]\n",
    "    newCon = all_sep(cam_list[i].contour_list, im_del_list)# newCon[color][fragment][coordination]\n",
    "    cam_list[i].frag_list = frag_list_fraged(newCon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnum = 3\n",
    "#new_img = np.zeros((cam_list[0].img.shape[0],cam_list[0].img.shape[1]),dtype=np.bool8)\n",
    "\n",
    "#for j in range(len(cam_list[cnum].frag_list)):\n",
    "#    for i in range(len(cam_list[cnum].frag_list[j])):\n",
    "#        curve = cam_list[cnum].frag_list[j][i][~np.isnan(cam_list[cnum].frag_list[j][i])].reshape((-1,2)).astype(int)\n",
    "#        new_img[curve[:,1],curve[:,0]]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#fig = plt.figure(figsize = (20, 20))\n",
    "#fig.patch.set_alpha(0.)\n",
    "## 3DAxesを追加\n",
    "#ax = fig.add_subplot(111)\n",
    "#plt.imshow(new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 衝突判定\n",
    "def para2cood_S(para_list):\n",
    "    return np.array([[0, -c/b] for a,b,c in para_list])\n",
    "\n",
    "def para2cood_F(para_list):\n",
    "    return np.array([[1920, -(1920*a+c)/b] for a,b,c in para_list])\n",
    "\n",
    "def all_pa2co(para_list):\n",
    "    epi_cood_S = []\n",
    "    epi_cood_F = []\n",
    "    for color in para_list:\n",
    "        color_list_S = []\n",
    "        color_list_F = []\n",
    "        for frag in color:\n",
    "            S_cood = para2cood_S(frag.squeeze())\n",
    "            F_cood = para2cood_F(frag.squeeze())\n",
    "            color_list_S.append(S_cood)\n",
    "            color_list_F.append(F_cood)\n",
    "        epi_cood_S.append(color_list_S)\n",
    "        epi_cood_F.append(color_list_F)\n",
    "    return epi_cood_S, epi_cood_F # epi_cood[color][frag]\n",
    "\n",
    "def get_frag_cood(frag_list):\n",
    "    cood_S = []\n",
    "    cood_F = []\n",
    "    for color in frag_list:\n",
    "        col_S = np.array([frag[0] for frag in color])\n",
    "        col_F = np.array([frag[-1] for frag in color])\n",
    "        cood_S.append(col_S)\n",
    "        cood_F.append(col_F)\n",
    "    return cood_S, cood_F # cood_S[color][frag]\n",
    "\n",
    "def coll_t1_t2(epi_cood_S, epi_cood_F, cood_S, cood_F):\n",
    "    epi_cood_S_bro = np.repeat(epi_cood_S,len(cood_S),axis=0).reshape((epi_cood_S.shape[0],len(cood_S),epi_cood_S.shape[1]))\n",
    "    epi_cood_F_bro = np.repeat(epi_cood_F,len(cood_S),axis=0).reshape((epi_cood_F.shape[0],len(cood_S),epi_cood_F.shape[1]))\n",
    "    v = cood_S - epi_cood_S_bro\n",
    "    v2 = cood_F - cood_S\n",
    "    v1 = epi_cood_F_bro - epi_cood_S_bro\n",
    "    t1 = np.cross(v, v2)/np.cross(v1, v2)\n",
    "    t2 = np.cross(v, v1)/np.cross(v1, v2)\n",
    "    return t1, t2\n",
    "\n",
    "def coll_det(t1, t2):\n",
    "    t1_t = np.array((t1 <= 1) & (t1 > 0),dtype=np.int16)\n",
    "    t2_t = np.array((t2 <= 1) & (t2 > 0),dtype=np.int16)\n",
    "    count_c = np.array(t1_t + t2_t == 2, dtype=np.int64)\n",
    "    #surport_idx = np.argmax(np.sum(count_c,axis=0))\n",
    "    count_c = np.sum(count_c,axis=0)\n",
    "    sorted_count_c = np.argsort(count_c)\n",
    "    count_c = np.where(sorted_count_c > np.max(sorted_count_c)-10)[0]\n",
    "    return count_c#surport_idx\n",
    "\n",
    "def make_piar_list(epi_cood_S, epi_cood_F, cood_S, cood_F):\n",
    "    img_list=[]\n",
    "    for epi_S_col, epi_F_col, S_col, F_col in zip(epi_cood_S, epi_cood_F, cood_S, cood_F):\n",
    "        color_list = []\n",
    "        if len(epi_S_col) == 0 or len(S_col) == 0:\n",
    "            img_list.append(color_list)\n",
    "            continue\n",
    "        for epi_S_frag, epi_F_frag in zip(epi_S_col, epi_F_col):\n",
    "            t1, t2 = coll_t1_t2(epi_S_frag, epi_F_frag, S_col, F_col)\n",
    "            surport_idx = coll_det(t1, t2)\n",
    "            color_list.append(surport_idx)\n",
    "        img_list.append(color_list)\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_and_key_gen(pair):\n",
    "    pair_list = {}\n",
    "    F = cam_pairs_F[pair]\n",
    "    frags_para12 = epilines_para(cam_list[pair[0]].frag_list, F) # frags_para[色][frag]\n",
    "    frags_para21 = epilines_para(cam_list[pair[1]].frag_list, F.T)\n",
    "\n",
    "    cood_S, cood_F = get_frag_cood(cam_list[pair[1]].frag_list)\n",
    "    epi_cood_S, epi_cood_F = all_pa2co(frags_para12)\n",
    "    img_list1 = make_piar_list(epi_cood_S, epi_cood_F, cood_S, cood_F)\n",
    "\n",
    "    cood_S, cood_F = get_frag_cood(cam_list[pair[0]].frag_list)\n",
    "    epi_cood_S, epi_cood_F = all_pa2co(frags_para21)\n",
    "    img_list2 = make_piar_list(epi_cood_S, epi_cood_F, cood_S, cood_F)\n",
    "\n",
    "    pair_list[((pair[0],pair[1]), \"F\")] = img_list1\n",
    "    pair_list[((pair[0],pair[1]), \"R\")] = img_list2\n",
    "    return pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 55min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import joblib\n",
    "result = joblib.Parallel(n_jobs=-1)(joblib.delayed(pair_and_key_gen)(i) for i in cam_pairs_F)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_list = {}\n",
    "for i in result:\n",
    "    pair_list.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair_list[key][color][curve][pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線と点の衝突判定\n",
    "def PL_coll(pair, pair_list, cam_list):\n",
    "    F = cam_pairs_F[pair[0]]\n",
    "    if pair[1] == \"F\":\n",
    "        frags_para = epilines_para(cam_list[pair[0][0]].frag_list, F) # frags_para[色][frag]\n",
    "        epi_cood_S, epi_cood_F = all_pa2co(frags_para)\n",
    "        camL_idx = pair[0][1]\n",
    "    elif pair[1] == \"R\":\n",
    "        frags_para = epilines_para(cam_list[pair[0][1]].frag_list, F.T)\n",
    "        epi_cood_S, epi_cood_F = all_pa2co(frags_para)\n",
    "        camL_idx = pair[0][0]\n",
    "\n",
    "    im_list = []\n",
    "    for pair_col, col_part, epi_S_col, epi_F_col in zip(pair_list[pair], cam_list[camL_idx].frag_list, epi_cood_S, epi_cood_F):\n",
    "        col_list=[]\n",
    "        for pair_frag, epi_S_frag, epi_F_frag in zip(pair_col, epi_S_col, epi_F_col):\n",
    "            f_list = []\n",
    "            for pair_frag_each in pair_frag:\n",
    "                pts = col_part[pair_frag_each] # 対応するフラグメント\n",
    "                v1 = epi_F_frag - epi_S_frag\n",
    "                v1_n = (v1[:,0]**2+v1[:,1]**2)**(1/2)\n",
    "                v1_n = np.stack([v1_n, v1_n], axis=1)\n",
    "                v1 = v1/v1_n\n",
    "\n",
    "                v1_bro = np.repeat(v1,len(pts),axis=0).reshape((v1.shape[0],len(pts),v1.shape[1]))\n",
    "                epi_cood_S_bro = np.repeat(epi_S_frag,len(pts),axis=0).reshape((epi_S_frag.shape[0],len(pts),epi_S_frag.shape[1]))\n",
    "\n",
    "                v2 = pts - epi_cood_S_bro\n",
    "                v2_n = (v2[:,:,0]**2+v2[:,:,1]**2)**(1/2)\n",
    "                v2_n = np.stack([v2_n, v2_n], axis=2)\n",
    "                v2 = v2/v2_n\n",
    "                con_det = np.cross(v1_bro, v2)\n",
    "                f_list.append(np.where(np.abs(con_det) <= 0.001))\n",
    "            col_list.append(f_list)\n",
    "        im_list.append(col_list)\n",
    "        \n",
    "    return im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点と線の衝突判定\n",
    "def coll_dict_gen(pair):\n",
    "    coll_dict = {}\n",
    "    im_list = PL_coll(pair, pair_list, cam_list)\n",
    "    coll_dict[pair] = im_list\n",
    "    return coll_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    954\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 955\u001b[1;33m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    956\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    560\u001b[0m         \"\"\"\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\executor.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self, kill_workers)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 self._temp_folder_manager._try_delete_folder(\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[0mallow_non_empty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m                 )\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36m_try_delete_folder\u001b[1;34m(self, allow_non_empty, context_id)\u001b[0m\n\u001b[0;32m    648\u001b[0m                 self._try_delete_folder(\n\u001b[1;32m--> 649\u001b[1;33m                     \u001b[0mallow_non_empty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_non_empty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    650\u001b[0m                 )\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36m_try_delete_folder\u001b[1;34m(self, allow_non_empty, context_id)\u001b[0m\n\u001b[0;32m    654\u001b[0m                 delete_folder(\n\u001b[1;32m--> 655\u001b[1;33m                     \u001b[0mtemp_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_non_empty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_non_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m                 )\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\disk.py\u001b[0m in \u001b[0;36mdelete_folder\u001b[1;34m(folder_path, onerror, allow_non_empty)\u001b[0m\n\u001b[0;32m    118\u001b[0m                         shutil.rmtree(\n\u001b[1;32m--> 119\u001b[1;33m                             \u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                         )\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1062\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1064\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1065\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pickle_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 757\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;31m# created. This 'hack' requires a private, low-level operation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             self._workers._temp_folder_manager._unlink_temporary_resources(\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0mcontext_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             )\n\u001b[0;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36m_unlink_temporary_resources\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m                     resource_tracker.maybe_unlink(\n\u001b[1;32m--> 625\u001b[1;33m                         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"file\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                     )\n\u001b[0;32m    627\u001b[0m                 self._try_delete_folder(\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py\u001b[0m in \u001b[0;36mmaybe_unlink\u001b[1;34m(self, name, rtype)\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;34m'''Decrement the refcount of a resource, and delete it if it hits 0'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MAYBE_UNLINK\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py\u001b[0m in \u001b[0;36m_send\u001b[1;34m(self, cmd, name, rtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;31m# bytes are atomic, and that PIPE_BUF >= 512\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'name too long'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mnbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mnbytes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = joblib.Parallel(n_jobs=-1)(joblib.delayed(coll_dict_gen)(i) for i in pair_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "coll_dict = {}\n",
    "for i in result:\n",
    "    coll_dict.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_pair(coll_list):\n",
    "    pool_i = []\n",
    "    pool_j = []\n",
    "    pre_i = None\n",
    "    pre_j = None\n",
    "    pt = 1\n",
    "    for i, j in zip(coll_list[0], coll_list[1]):\n",
    "        if i in pool_i:\n",
    "            if pt == 1:\n",
    "                continue\n",
    "            elif pt == 0:\n",
    "                if j not in pool_j:\n",
    "                    pool_i.pop()\n",
    "                    pool_j.pop()\n",
    "                    pool_i.append(i)\n",
    "                    pool_j.append(j)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        elif i not in pool_i:\n",
    "            if j in pool_j:\n",
    "                pt = 0\n",
    "            else:\n",
    "                pt = 1\n",
    "            pool_i.append(i)\n",
    "            pool_j.append(j)\n",
    "    return np.array([pool_i, pool_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-0c2d73f3207c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mf_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0meach_frag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfrag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                 \u001b[0mnew_pair\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt_pair\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meach_frag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m                 \u001b[0mf_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_pair\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mcol_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-72070d31b3ba>\u001b[0m in \u001b[0;36mpt_pair\u001b[1;34m(coll_list)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpre_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoll_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoll_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpool_i\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# 点の一対一対応\n",
    "pair_pt = {}\n",
    "for i in coll_dict:\n",
    "    im_list = []\n",
    "    for col in coll_dict[i]:\n",
    "        col_list = []\n",
    "        for frag in col:\n",
    "            f_list = []\n",
    "            for each_frag in frag:\n",
    "                new_pair = pt_pair(each_frag)\n",
    "                f_list.append(new_pair)\n",
    "            col_list.append(f_list)\n",
    "        im_list.append(col_list)\n",
    "    pair_pt[i] = im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FR_frags(dict_tag):\n",
    "    if dict_tag[1] == \"F\":\n",
    "        part = cam_list[dict_tag[0][0]].frag_list\n",
    "        counterpart = cam_list[dict_tag[0][1]].frag_list\n",
    "        return part, counterpart\n",
    "        \n",
    "    elif i[1] == \"R\":\n",
    "        part = cam_list[dict_tag[0][1]].frag_list\n",
    "        counterpart = cam_list[dict_tag[0][0]].frag_list\n",
    "        return part, counterpart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_circle_array(img, co, size, color, r):\n",
    "    for i in range(len(co)):\n",
    "        img = cv2.circle(img, co[i], 10, (0,100,0), -1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnum = 0\n",
    "new_img = np.zeros((cam_list[0].img.shape[0],cam_list[0].img.shape[1]),dtype=np.bool8)\n",
    "copy_img = np.copy(cam_list[cnum].img)\n",
    "for j in range(len(cam_list[cnum].frag_list)):\n",
    "    for i in range(len(cam_list[cnum].frag_list[j])):\n",
    "        curve = cam_list[cnum].frag_list[j][i][~np.isnan(cam_list[cnum].frag_list[j][i])].reshape((-1,2)).astype(int)\n",
    "        if i == 6:\n",
    "            img = cv2_circle_array(copy_img, curve, 10, (0,0,255), -1)\n",
    "        #new_img[curve[:,1],curve[:,0]]=True\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (20, 20))\n",
    "fig.patch.set_alpha(0.)\n",
    "# 3DAxesを追加\n",
    "ax = fig.add_subplot(111)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnum = 1\n",
    "new_img = np.zeros((cam_list[0].img.shape[0],cam_list[0].img.shape[1]),dtype=np.bool8)\n",
    "copy_img = np.copy(cam_list[cnum].img)\n",
    "for j in range(len(cam_list[cnum].frag_list)):\n",
    "    for i in range(len(cam_list[cnum].frag_list[j])):\n",
    "        curve = cam_list[cnum].frag_list[j][i][~np.isnan(cam_list[cnum].frag_list[j][i])].reshape((-1,2)).astype(int)\n",
    "        if i == 27:\n",
    "            img = cv2_circle_array(copy_img, curve, 10, (0,0,255), -1)\n",
    "        #new_img[curve[:,1],curve[:,0]]=True\n",
    "            break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize = (20, 20))\n",
    "fig.patch.set_alpha(0.)\n",
    "# 3DAxesを追加\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "plt.imshow(img)#new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 座標でdictを作る\n",
    "coordinate_dict = {}\n",
    "for i in pair_list:\n",
    "    pair_coordinate = []\n",
    "    part, counterpart = FR_frags(i)\n",
    "    for part_col, cpart_col, pair_col, PtPair_col in zip(part, counterpart, pair_list[i], pair_pt[i]):\n",
    "        col_list = []\n",
    "        for part_frag, pair, pt_idx in zip(part_col, pair_col, PtPair_col):\n",
    "            for each_pair, each_pt_idx in zip(pair, pt_idx):\n",
    "                if each_pt_idx[0].size != 0:\n",
    "                    col_list.append((np.array([part_frag[each_pt_idx[0]], cpart_col[each_pair][each_pt_idx[1]]])))\n",
    "        pair_coordinate.append(col_list)\n",
    "    coordinate_dict[i] = pair_coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FR_check(dict_tag):\n",
    "    if dict_tag[1] == \"F\":\n",
    "        P1 = cam_list[dict_tag[0][0]].P\n",
    "        P2 = cam_list[dict_tag[0][1]].P\n",
    "        F = cam_pairs_F[dict_tag[0]]\n",
    "        return P1, P2, F\n",
    "    elif dict_tag[1] == \"R\":\n",
    "        P1 = cam_list[dict_tag[0][1]].P\n",
    "        P2 = cam_list[dict_tag[0][0]].P\n",
    "        F = cam_pairs_F[dict_tag[0]].T\n",
    "        return P1, P2, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_points(pts_list):\n",
    "    sep_list = []\n",
    "    root = np.transpose(pts_list[0], (1, 0, 2))\n",
    "    length = len(root)-1\n",
    "    sep_list.append(length)\n",
    "    for i, pt in enumerate(pts_list):\n",
    "        pt = np.transpose(pt, (1, 0, 2))\n",
    "        if i == 0:\n",
    "            continue\n",
    "        root = np.concatenate([root, pt], 0)\n",
    "        length += len(pt)\n",
    "        sep_list.append(length)\n",
    "    return root, sep_list\n",
    "\n",
    "def sep_array(tri_pts, sep_list):\n",
    "    # 一つの輪郭に対し削除リストから削除\n",
    "    start = 0\n",
    "    newArray = []\n",
    "    for d in sep_list:\n",
    "        if tri_pts[start:d].size != 0:\n",
    "            newArray.append(tri_pts[start:d])\n",
    "        start = d\n",
    "\n",
    "    if tri_pts[start:].size != 0:\n",
    "        newArray.append(tri_pts[start:])\n",
    "    return newArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "TDlines = []\n",
    "for i, j in enumerate(coordinate_dict):\n",
    "    \n",
    "    pts = coordinate_dict[j]\n",
    "    P1_ori, P2_ori, F_ori = FR_check(j)\n",
    "    #pt, sep_list = connect_points(pts)\n",
    "    temp_TDlines = []\n",
    "    for pt in pts:\n",
    "        pt = np.transpose(pt, (1, 0, 2))\n",
    "        F = np.broadcast_to(F_ori, (pt.shape[0],3,3))\n",
    "        P1 = np.broadcast_to(P1_ori, (pt.shape[0],3,4))\n",
    "        P2 = np.broadcast_to(P2_ori, (pt.shape[0],3,4))\n",
    "        newcoords= np.array(list(map(min_dist, F, pt[:,1,:], pt[:,0,:])))\n",
    "        tri_pt = np.array(list(map(tri, P1, P2, newcoords[:,1,:], newcoords[:,0,:])))\n",
    "        #pts_array = sep_array(tri_pt, sep_list)\n",
    "        temp_TDlines.append(tri_pt)\n",
    "    TDlines.append(temp_TDlines)\n",
    "    print((i+1)/len(coordinate_dict)*100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TDlines = {}\n",
    "for i, j in enumerate(coordinate_dict):\n",
    "    \n",
    "    pts = coordinate_dict[j]\n",
    "    P1_ori, P2_ori, F_ori = FR_check(j)\n",
    "    #pt, sep_list = connect_points(pts)\n",
    "    temp_TDlines = []\n",
    "    for pts_col in pts:\n",
    "        col_list = []\n",
    "        for pt in pts_col:\n",
    "            pt = np.transpose(pt, (1, 0, 2))\n",
    "            F = np.broadcast_to(F_ori, (pt.shape[0],3,3))\n",
    "            P1 = np.broadcast_to(P1_ori, (pt.shape[0],3,4))\n",
    "            P2 = np.broadcast_to(P2_ori, (pt.shape[0],3,4))\n",
    "            newcoords= np.array(list(map(min_dist, F, pt[:,1,:], pt[:,0,:])))\n",
    "            tri_pt = np.array(list(map(tri, P1, P2, newcoords[:,1,:], newcoords[:,0,:])))\n",
    "            #pts_array = sep_array(tri_pt, sep_list)\n",
    "            col_list.append(tri_pt)\n",
    "        temp_TDlines.append(col_list)\n",
    "    TDlines[j] = temp_TDlines\n",
    "    print((i+1)/len(coordinate_dict)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excluded_Parray(ex_tag):\n",
    "    P_dict = {}\n",
    "    for i, cam in enumerate(cam_list):\n",
    "        if i in ex_tag:\n",
    "            continue\n",
    "        P_dict[i] = cam.P\n",
    "    return P_dict\n",
    "\n",
    "def dot_P_frag(P, frag):\n",
    "    repro_frag = []\n",
    "    for pt in frag:\n",
    "        repro_pt = np.dot(P, pt)\n",
    "        repro_pt = np.array(normalization(repro_pt))\n",
    "        repro_frag.append(repro_pt)\n",
    "    return np.array(repro_frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "# \n",
    "#print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "#print(\" ------------------------------------ \")\n",
    "#for var_name in dir():\n",
    "#    if not var_name.startswith(\"_\"):\n",
    "#        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in TDlines:\n",
    "    with open(r\"temp/{0}_{1}_{2}.TDlines\".format(tag[0][0],tag[0][1],tag[1]),\"wb\") as f:\n",
    "        pickle.dump(TDlines[tag], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "del TDlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reprojection_dict = {}\n",
    "j = 0\n",
    "for tag in tags:\n",
    "    temp_reprojection_dict = {}\n",
    "    P_dict = excluded_Parray(tag[0])\n",
    "    for P_tag in P_dict:\n",
    "        P = P_dict[P_tag]\n",
    "        P_list = []\n",
    "        with open(r\"temp/{0}_{1}_{2}.TDlines\".format(tag[0][0],tag[0][1],tag[1]), 'rb') as f:\n",
    "            TDlines_taged = pickle.load(f)\n",
    "        for col in TDlines_taged:\n",
    "            col_list = []\n",
    "            for i, frag in enumerate(col):\n",
    "                frag = frag.reshape((-1,3))\n",
    "                frag = np.concatenate([frag, np.ones(len(frag)).reshape((len(frag), 1))],1) # 末尾に1を追加 (X, Y, Z, 1)\n",
    "                reprojection = dot_P_frag(P, frag)\n",
    "                col_list.append(reprojection)\n",
    "            P_list.append(col_list)\n",
    "        temp_reprojection_dict[P_tag] = P_list\n",
    "    reprojection_dict[tag] = temp_reprojection_dict\n",
    "    #j += 1\n",
    "    #print(j/len(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reprojection_gen(tag):\n",
    "    reprojection_dict = {}\n",
    "    temp_reprojection_dict = {}\n",
    "    P_dict = excluded_Parray(tag[0])\n",
    "    for P_tag in P_dict:\n",
    "        P = P_dict[P_tag]\n",
    "        P_list = []\n",
    "        with open(r\"temp/{0}_{1}_{2}.TDlines\".format(tag[0][0],tag[0][1],tag[1]), 'rb') as f:\n",
    "            TDlines_taged = pickle.load(f)\n",
    "        for col in TDlines_taged:\n",
    "            col_list = []\n",
    "            for i, frag in enumerate(col):\n",
    "                frag = frag.reshape((-1,3))\n",
    "                frag = np.concatenate([frag, np.ones(len(frag)).reshape((len(frag), 1))],1) # 末尾に1を追加 (X, Y, Z, 1)\n",
    "                reprojection = dot_P_frag(P, frag)\n",
    "                col_list.append(reprojection)\n",
    "            P_list.append(col_list)\n",
    "        temp_reprojection_dict[P_tag] = P_list\n",
    "    #reprojection_dict[tag] = temp_reprojection_dict\n",
    "    with open(r\"temp/{0}_{1}_{2}.reprojection_dict\".format(tag[0][0],tag[0][1],tag[1]),\"wb\") as f:\n",
    "        pickle.dump(temp_reprojection_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 12.3min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 15.9min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 18.5min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 22.6min\n",
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 31.6min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 35.0min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 40.9min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 44.4min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 50.1min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 55.8min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 61.0min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 66.9min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed: 71.5min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed: 75.9min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 82.9min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed: 90.3min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed: 95.9min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 102.7min\n",
      "[Parallel(n_jobs=-1)]: Done 457 tasks      | elapsed: 113.1min\n",
      "[Parallel(n_jobs=-1)]: Done 488 tasks      | elapsed: 122.3min\n",
      "[Parallel(n_jobs=-1)]: Done 521 tasks      | elapsed: 129.3min\n",
      "[Parallel(n_jobs=-1)]: Done 554 tasks      | elapsed: 144.3min\n",
      "[Parallel(n_jobs=-1)]: Done 589 tasks      | elapsed: 154.9min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed: 164.4min\n",
      "[Parallel(n_jobs=-1)]: Done 661 tasks      | elapsed: 177.0min\n",
      "[Parallel(n_jobs=-1)]: Done 698 tasks      | elapsed: 188.2min\n",
      "[Parallel(n_jobs=-1)]: Done 737 tasks      | elapsed: 199.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 212.6min\n",
      "[Parallel(n_jobs=-1)]: Done 817 tasks      | elapsed: 223.2min\n",
      "[Parallel(n_jobs=-1)]: Done 858 tasks      | elapsed: 233.8min\n",
      "[Parallel(n_jobs=-1)]: Done 901 tasks      | elapsed: 245.4min\n",
      "[Parallel(n_jobs=-1)]: Done 944 tasks      | elapsed: 260.6min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed: 274.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1034 tasks      | elapsed: 290.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1081 tasks      | elapsed: 306.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1128 tasks      | elapsed: 320.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1177 tasks      | elapsed: 337.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 353.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1277 tasks      | elapsed: 370.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1328 tasks      | elapsed: 387.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1381 tasks      | elapsed: 405.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1434 tasks      | elapsed: 422.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1489 tasks      | elapsed: 441.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1544 tasks      | elapsed: 458.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1601 tasks      | elapsed: 481.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1658 tasks      | elapsed: 507.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1717 tasks      | elapsed: 531.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 554.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1837 tasks      | elapsed: 576.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1898 tasks      | elapsed: 596.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1961 tasks      | elapsed: 617.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2024 tasks      | elapsed: 635.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2089 tasks      | elapsed: 656.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2154 tasks      | elapsed: 674.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2221 tasks      | elapsed: 693.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2288 tasks      | elapsed: 712.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2357 tasks      | elapsed: 733.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 756.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2497 tasks      | elapsed: 777.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2568 tasks      | elapsed: 800.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2641 tasks      | elapsed: 830.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2668 out of 2668 | elapsed: 841.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14h 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import joblib\n",
    "result = joblib.Parallel(n_jobs=-1,verbose=10)(joblib.delayed(reprojection_gen)(tag) for tag in tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_contour(contour_list):\n",
    "    con_list = []\n",
    "    for col in contour_list:\n",
    "        if len(col) == 0:\n",
    "            con_list.append(np.empty((1,2)))\n",
    "            continue\n",
    "        A = np.concatenate(col).reshape((-1, 2))\n",
    "        con_list.append(A)\n",
    "    return con_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_distance(repro_P, contour_P):\n",
    "    contour_P = connect_contour(contour_P)\n",
    "    distance_list = []\n",
    "    for repro_col, con_col in zip(repro_P, contour_P):\n",
    "        col_list = []\n",
    "        for repro_frag in repro_col:\n",
    "            repro_frag_bro = np.repeat(repro_frag, len(con_col),axis=0).reshape((repro_frag.shape[0], len(con_col), repro_frag.shape[1]))\n",
    "            distance = (np.sum((con_col - repro_frag_bro)**2,axis=2))**(1/2)\n",
    "            col_list.append(distance)\n",
    "        distance_list.append(col_list)\n",
    "    return distance_list\n",
    "\n",
    "def distance_check(distance_list):\n",
    "    dist_check_list = []\n",
    "    ac_list = []\n",
    "    for col in distance_list:\n",
    "        col_list = []\n",
    "        ac_col_list = []\n",
    "        for frag in col:\n",
    "            ac = np.array((np.min(frag,axis=1)) < 10,dtype=np.int64) # 条件:10 pixel以内\n",
    "            col_list.append(sum(ac)/len(ac))\n",
    "            ac_col_list.append(ac)\n",
    "        ac_list.append(ac_col_list)\n",
    "        dist_check_list.append(np.array(col_list))\n",
    "    return ac_list, dist_check_list\n",
    "\n",
    "def P_dict_check(repro_dict_taged):\n",
    "    P_list = []\n",
    "    P_ac_list = []\n",
    "    for P_tag in repro_dict_taged:\n",
    "        repro_P = repro_dict_taged[P_tag]\n",
    "        contour_P = cam_list[P_tag].contour_list\n",
    "        distance_list = cal_distance(repro_P, contour_P)\n",
    "        ac_list, dist_check_list = distance_check(distance_list)\n",
    "        P_list.append(dist_check_list)\n",
    "        P_ac_list.append(ac_list)\n",
    "    P_check = np.array(P_list)\n",
    "    return ac_list, P_ac_list, P_check\n",
    "\n",
    "def P_check_integration(P_check):\n",
    "    check_list = []\n",
    "    for col in range(P_check.shape[1]):\n",
    "        temp_list = []\n",
    "        for img in P_check[:,col]:\n",
    "            temp = np.array(img > 0.8,dtype=np.int64)# 曲線中の何割が閾値以内か\n",
    "            temp_list.append(temp)\n",
    "        col_check = np.sum(np.array(temp_list),axis=0)\n",
    "        check_list.append(col_check)\n",
    "    return check_list\n",
    "\n",
    "def ac_list_integration(P_ac_list):\n",
    "    inter_ac = []\n",
    "    for i, col in enumerate(P_ac_list[0]):\n",
    "        col_list = []\n",
    "        for j in range(len(col)):\n",
    "            temp_array = np.zeros(len(P_ac_list[0][i][j]))\n",
    "            for img in P_ac_list:\n",
    "                temp_array += img[i][j]\n",
    "            col_list.append(temp_array)\n",
    "        inter_ac.append(col_list)\n",
    "    return inter_ac\n",
    "    \n",
    "\n",
    "def gen_support_dict(tags):\n",
    "    support_dict = {}\n",
    "    for tag in tags:\n",
    "        with open(r\"temp/{0}_{1}_{2}.reprojection_dict\".format(tag[0][0],tag[0][1],tag[1]), 'rb') as f:\n",
    "            repro_dict_taged = pickle.load(f)\n",
    "        #repro_dict_taged = reprojection_dict[tag]\n",
    "        _, P_ac_list, P_check = P_dict_check(repro_dict_taged)\n",
    "        check_list = P_check_integration(P_check)\n",
    "        inter_ac = ac_list_integration(P_ac_list)\n",
    "        #support_dict[tag] = (check_list, inter_ac)\n",
    "        with open(r\"temp/{0}_{1}_{2}.support_dict\".format(tag[0][0],tag[0][1],tag[1]),\"wb\") as f:\n",
    "            pickle.dump((check_list, inter_ac), f)\n",
    "    return #support_dict\n",
    "\n",
    "def gen_support(tag):\n",
    "    if tag[1] == \"R\":\n",
    "        return\n",
    "    \n",
    "    with open(r\"temp/{0}_{1}_{2}.reprojection_dict\".format(tag[0][0],tag[0][1],tag[1]), 'rb') as f:\n",
    "        repro_dict_taged = pickle.load(f)\n",
    "    #repro_dict_taged = reprojection_dict[tag]\n",
    "    _, P_ac_list, P_check = P_dict_check(repro_dict_taged)\n",
    "    check_list = P_check_integration(P_check)\n",
    "    inter_ac = ac_list_integration(P_ac_list)\n",
    "    #support_dict[tag] = (check_list, inter_ac)\n",
    "    with open(r\"temp/{0}_{1}_{2}.support_dict\".format(tag[0][0],tag[0][1],tag[1]),\"wb\") as f:\n",
    "        pickle.dump((check_list, inter_ac), f)\n",
    "        \n",
    "    return #support_dict\n",
    "\n",
    "def get_tilt(curve):\n",
    "    tilt_list = []\n",
    "    for i in renge(curve):\n",
    "        if i == 0:\n",
    "            tilt = (curve[i]-curve[i+1])\n",
    "            \n",
    "        elif i == len(curve) - 1:\n",
    "            tilt = (curve[i-1]-curve[i])\n",
    "            \n",
    "        else:\n",
    "            tilt = (curve[i-1]-curve[i+1])/2\n",
    "        tilt_list.append(tilt)\n",
    "    return np.array(tilt_list)\n",
    "\n",
    "def tilt_comparison(tilt1, tilt2):\n",
    "    angle1 = np.arctan(tilt1)\n",
    "    angle2 = np.arctan(tilt2)\n",
    "    return np.abs(angle1-angle2)\n",
    "\n",
    "def tilt_filter(curve1, curve2):\n",
    "    tilt1 = get_tilt(curve1)\n",
    "    tilt2 = get_tilt(curve2)\n",
    "    tilt_com_list = tilt_comparison(tilt1, tilt2)\n",
    "    return tilt_com_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_support_dict(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open('tag.pickle', 'rb') as f:\n",
    "    tags = pickle.load(f)\n",
    "\n",
    "with open('del_tag.pickle', 'rb') as f:\n",
    "    del_tags = pickle.load(f)\n",
    "    del_tags = np.array(del_tags).tolist()\n",
    "    \n",
    "for i in del_tags:\n",
    "    if i in tags:\n",
    "        tags.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "731"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   41.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 49.9min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed: 69.7min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 81.7min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed: 105.4min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 137.9min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 164.0min\n",
      "[Parallel(n_jobs=-1)]: Done  89 tasks      | elapsed: 207.8min\n",
      "[Parallel(n_jobs=-1)]: Done 104 tasks      | elapsed: 235.7min\n",
      "[Parallel(n_jobs=-1)]: Done 121 tasks      | elapsed: 284.0min\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed: 345.2min\n",
      "[Parallel(n_jobs=-1)]: Done 157 tasks      | elapsed: 391.1min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed: 435.9min\n",
      "[Parallel(n_jobs=-1)]: Done 197 tasks      | elapsed: 493.5min\n",
      "[Parallel(n_jobs=-1)]: Done 218 tasks      | elapsed: 538.8min\n",
      "[Parallel(n_jobs=-1)]: Done 241 tasks      | elapsed: 609.1min\n",
      "[Parallel(n_jobs=-1)]: Done 264 tasks      | elapsed: 672.3min\n",
      "[Parallel(n_jobs=-1)]: Done 289 tasks      | elapsed: 746.6min\n",
      "[Parallel(n_jobs=-1)]: Done 314 tasks      | elapsed: 818.4min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed: 908.3min\n",
      "[Parallel(n_jobs=-1)]: Done 368 tasks      | elapsed: 1007.6min\n",
      "[Parallel(n_jobs=-1)]: Done 397 tasks      | elapsed: 1111.4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import joblib\n",
    "result = joblib.Parallel(n_jobs=-1,verbose=10)(joblib.delayed(gen_support)(tag) for tag in tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_th = 5# サポート数\n",
    "curve_fragment = []\n",
    "for tag in TDlines:\n",
    "    #if tag[1] == \"R\":\n",
    "    #    continue\n",
    "    lines_list = TDlines[tag]\n",
    "    with open(r\"temp/{0}_{1}_{2}.tempfile\".format(tag[0][0],tag[0][1],tag[1]), 'rb') as f:\n",
    "        support_list, support_ac = pickle.load(f)\n",
    "    #support_list, support_ac = support_dict[tag][0], support_dict[tag][1]\n",
    "    tag_list = []\n",
    "    for col, sup_col, ac_col in zip(lines_list, support_list, support_ac):\n",
    "        col_curve_fragment = []\n",
    "        for frag, sup, sup_ac in zip(col, sup_col, ac_col):\n",
    "            if sup > 10:\n",
    "                frag = np.reshape(frag,(-1, 3))\n",
    "                frag = np.array([i for i,j in zip(frag, sup_ac >sup_th) if j])\n",
    "                col_curve_fragment.append(frag)\n",
    "        tag_list.append(col_curve_fragment)\n",
    "    curve_fragment.append(tag_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfs = [[],[],[],[],[],[],[],[],[],[],[],[],[]]\n",
    "for cols in curve_fragment:\n",
    "    for i in range(len(cols)):\n",
    "        if i == 0:\n",
    "            cfs[0] += cols[i]\n",
    "        if i == 1:\n",
    "            cfs[1] += cols[i]\n",
    "        if i == 2:\n",
    "            cfs[2] += cols[i]\n",
    "        if i == 3:\n",
    "            cfs[3] += cols[i]\n",
    "        if i == 4:\n",
    "            cfs[4] += cols[i]\n",
    "        if i == 5:\n",
    "            cfs[5] += cols[i]\n",
    "        if i == 6:\n",
    "            cfs[6] += cols[i]\n",
    "        if i == 7:\n",
    "            cfs[7] += cols[i]\n",
    "        if i == 8:\n",
    "            cfs[8] += cols[i]\n",
    "        if i == 9:\n",
    "            cfs[9] += cols[i]\n",
    "        if i == 10:\n",
    "            cfs[10] += cols[i]\n",
    "        if i == 11:\n",
    "            cfs[11] += cols[i]\n",
    "        if i == 12:\n",
    "            cfs[12] += cols[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "def plot_graph():\n",
    "    color_arr = np.array([[255,0,0],[0,255,0],[0,0,255],\n",
    "                             [255,255,0],[255,0,255],[0,255,255],\n",
    "                             [127,127,127],[127,0,127],[0,127,127]],dtype = np.int16)\n",
    "    j = 0\n",
    "    for i in range(len(cfs)):\n",
    "        for frag in cfs[i]:\n",
    "            if frag.size == 0:\n",
    "                continue\n",
    "            #print(frag)\n",
    "            \n",
    "            \n",
    "            x = frag[:,0]\n",
    "            y = frag[:,1]\n",
    "            z = frag[:,2]\n",
    "            data = [x,y,z]\n",
    "            try:\n",
    "                tck, u= interpolate.splprep(data, k=3)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            except TypeError:\n",
    "                pass\n",
    "            new = interpolate.splev(u, tck, der=0)\n",
    "            c = color_arr[i]/255\n",
    "            if j % 100 == 0:\n",
    "                ax.plot(new[0], new[2], new[1],\"-\",color=c)\n",
    "            \n",
    "            j+=1\n",
    "            \n",
    "        \n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "fig.patch.set_alpha(0.)\n",
    "# 3DAxesを追加\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 軸ラベルを設定\n",
    "ax.set_xlabel(\"x\", size = 14)\n",
    "ax.set_ylabel(\"z\", size = 14)\n",
    "ax.set_zlabel(\"y\", size = 14)\n",
    "ax.set_box_aspect((1,1,1))\n",
    "#ax.set_xticks(np.arange(-4,4,1))\n",
    "#ax.set_yticks(np.arange(-4,4,1))\n",
    "#ax.set_zticks(np.arange(-2,9,1))\n",
    "\n",
    "plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flatten_curve_frag = np.array(list(itertools.chain.from_iterable(_curve_fragment)))\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(flatten_curve_frag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "fig.patch.set_alpha(0.)\n",
    "# 3DAxesを追加\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 軸ラベルを設定\n",
    "ax.set_xlabel(\"x\", size = 14)\n",
    "ax.set_ylabel(\"z\", size = 14)\n",
    "ax.set_zlabel(\"y\", size = 14)\n",
    "ax.set_box_aspect((1,1,1))\n",
    "\n",
    "def plot_graph():\n",
    "    i = 0\n",
    "    for c_f in curve_fragment:\n",
    "        for frag in c_f:\n",
    "            if frag.size == 0:\n",
    "                continue\n",
    "            #print(frag)\n",
    "            \n",
    "            if i%100 == 0:\n",
    "                x = frag[:,0]\n",
    "                y = frag[:,1]\n",
    "                z = frag[:,2]\n",
    "                data = [x,y,z]\n",
    "                try:\n",
    "                    tck, u= interpolate.splprep(data, k=3)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "                except TypeError:\n",
    "                    pass\n",
    "                new = interpolate.splev(u, tck, der=0)\n",
    "\n",
    "                ax.plot(new[0], new[2], new[1],\"-\")\n",
    "                    #ax.plot(x, z, y,\"-\")\n",
    "            i += 1\n",
    "\n",
    "def plt_graph3d(angle):\n",
    "    ax.view_init(azim=angle*5)\n",
    "    \n",
    "# アニメーションを作成\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    func=plt_graph3d,\n",
    "    frames=72,\n",
    "    init_func=plot_graph,\n",
    "    interval=200\n",
    ")\n",
    "\n",
    "# imagemagickで作成したアニメーションをGIFで書き出す\n",
    "ani.save(\"48_rolling.gif\", writer=\"pillow\", savefig_kwargs={'transparent': True, 'facecolor': 'none'})\n",
    "#ani.save('48_anim.mp4', writer=\"ffmpeg\", savefig_kwargs={'transparent': True, 'facecolor': 'none'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"one_hole_leaf.curves\",\"wb\") as f:\n",
    "    pickle.dump(curve_fragment, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('py37cv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "8baeaee9d41a9ede74577397e936a2336300ab3dde63496ecc21a0a5b3548eb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
