{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pathlib\n",
    "import os\n",
    "from scipy.linalg import null_space\n",
    "import sympy\n",
    "import time\n",
    "import numba\n",
    "\n",
    "class Camera:\n",
    "    \n",
    "    def __init__(self, val):\n",
    "        self.img_num = val # カメラ番号（int;コンストラクタ）\n",
    "        \n",
    "        f = 8000/3\n",
    "        cx = 1920/2\n",
    "        cy = 1080/2\n",
    "        A = np.zeros((3,3))\n",
    "        A[0,0] = f\n",
    "        A[0,2] = cx\n",
    "        A[1,1] = f\n",
    "        A[1,2] = cy\n",
    "        A[2,2] = 1\n",
    "        \n",
    "        self.A = A # 内部パラメータ(ndarray)後から更新\n",
    "\n",
    "    def img_load(self):\n",
    "        folder_path = \"image\"\n",
    "        file_path = os.path.join(folder_path, str(self.img_num) + \".png\")\n",
    "        img = cv2.imread(file_path, 1)# BGRで読み込み\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.flip(img, 1)\n",
    "        self.img = img # 画像(ndarray)\n",
    "        \n",
    "    def contour_extraction(self):\n",
    "        \n",
    "        color_arr = np.array([[255,0,0],[0,255,0],[0,0,255],\n",
    "                             [255,255,0],[255,0,255],[0,255,255],\n",
    "                             [127,127,127],[127,0,127],[0,127,127]],dtype = np.int16)\n",
    "        masks = np.ones((self.img.shape[0], self.img.shape[1], len(color_arr)), dtype=np.uint8)\n",
    "        \n",
    "        for i, color in enumerate(color_arr):\n",
    "            lower = np.clip(color, 0, 255)\n",
    "            upper = np.clip(color, 0, 255)\n",
    "            img_mask = cv2.inRange(self.img, lower, upper)\n",
    "            masks[:,:,i] = img_mask\n",
    "        \n",
    "        #self.masks = masks # 色ごとのマスク(nd.array)\n",
    "        \n",
    "        contour_list = []\n",
    "\n",
    "        # 色ごとに輪郭（閉曲線）を抽出\n",
    "        for i in range(masks.shape[2]):\n",
    "            contours, hierarchy = cv2.findContours(masks[:,:,i],cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "            contour_list += contours\n",
    "        self.contour_list = contour_list # 輪郭のリスト(list,ndarray)\n",
    "\n",
    "        #self.frag_list = contours2fragments(self.contour_list) # フラグメントのリスト(list,ndarray)\n",
    "\n",
    "    def para_load(self):\n",
    "\n",
    "        folder_path = pathlib.Path(\"view_mat\")\n",
    "        file_path = os.path.join(folder_path, str(self.img_num)+\".csv\")\n",
    "        self.Rt = np.loadtxt(file_path, delimiter=\"\\t\")\n",
    "        self.P = np.dot(self.A, self.Rt[0:3,0:4])\n",
    "        \n",
    "        #folder_path = pathlib.Path(\"cam_pos_rot\")\n",
    "        #file_path = os.path.join(folder_path, str(self.img_num)+\".csv\")\n",
    "        self.cam_world_cood = -np.dot(self.Rt[0:3,0:3].T, self.Rt[0:3,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 曲線分割\n",
    "def split_list(contour_length, max_frag_len=100, min_frag_len=40, min_overrap=10):\n",
    "    \n",
    "    # 輪郭のフラグメントの位置を指定(最小40 pixl)\n",
    "    if contour_length > max_frag_len:\n",
    "        pass\n",
    "    \n",
    "    elif contour_length < min_frag_len:\n",
    "        return None\n",
    "    \n",
    "    elif contour_length == min_frag_len:\n",
    "        return [[0,min_frag_len-1]]\n",
    "    \n",
    "    else:\n",
    "        max_frag_len = contour_length\n",
    "    \n",
    "    step0 = np.random.randint(min_frag_len, max_frag_len) # 一つ目のフラグメントの長さ（40から100）\n",
    "    sep_list = [[0,step0]]\n",
    "    back = np.random.randint(min_overrap, step0-1) # フラグメントを重ねるために戻す分を決める（最小10 pixl）\n",
    "    next_start = step0 - back\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # 戻った分(back)より進む\n",
    "        if back+1 > min_frag_len:\n",
    "            step = np.random.randint(back+1, max_frag_len)\n",
    "        else:\n",
    "            step = np.random.randint(min_frag_len, max_frag_len)\n",
    "\n",
    "        full_length = next_start + step\n",
    "        sept = [next_start, full_length]\n",
    "        sep_list.append(sept)\n",
    "        back = np.random.randint(10, step-1)\n",
    "        next_start = full_length - back\n",
    "\n",
    "        # 終了判定\n",
    "        if full_length > contour_length:\n",
    "            break\n",
    "    \n",
    "    # 超過した分戻す（長さはそのまま）\n",
    "    difference = sep_list[-1][1] - (contour_length-1)\n",
    "    sep_list[-1][0] -= difference\n",
    "    sep_list[-1][1] -= difference\n",
    "    \n",
    "    return sep_list\n",
    "\n",
    "\n",
    "def contours_split(contour):\n",
    "    \n",
    "    #contour.shape == (N, 2)\n",
    "    contour_length = contour.shape[0]\n",
    "    sp_list = split_list(contour_length)\n",
    "    \n",
    "    if sp_list == None:\n",
    "        return None\n",
    "    \n",
    "    frag_list = []\n",
    "    # 位置のリスト通りにスライス\n",
    "    for sp in sp_list:\n",
    "        #print(sp)\n",
    "        frag_list.append(contour[sp[0]:sp[1],:])\n",
    "\n",
    "    return frag_list\n",
    "\n",
    "\n",
    "def all_fraged(contours_list):\n",
    "    \n",
    "    # 輪郭のリストからフラグメントのリストを得る\n",
    "    frags_list = []\n",
    "\n",
    "    #for i in contours_list:\n",
    "    #temp_list = []\n",
    "    frags = []\n",
    "    for j in contours_list:\n",
    "        temp_frags = contours_split(j.squeeze())\n",
    "            \n",
    "        if temp_frags != None:\n",
    "            frags += temp_frags\n",
    "\n",
    "    #if frags != []:\n",
    "    #    frags_list.append(frags)\n",
    "    \n",
    "    return frags\n",
    "\n",
    "#def frag_list_fraged(frags_list):# frags_list[色][輪郭][sep][座標]\n",
    "#    img_frag_list = []\n",
    "#    for frag in frags_list:\n",
    "#        color_frag = all_fraged(frag)\n",
    "#        img_frag_list.append(color_frag)\n",
    "#    return img_frag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera対応\n",
    "def dim3_distance(vec1, vec2):\n",
    "    return sum((vec1-vec2)**2)\n",
    "\n",
    "def camera_correspondence(cam_list):\n",
    "    vec_list = []\n",
    "    for i,cam in enumerate(cam_list):\n",
    "        vec_list.append(cam_list[i].cam_world_cood)\n",
    "        #print(cam_list[i].cam_world_cood)\n",
    "    pair_list = []\n",
    "    for i, vec1 in enumerate(vec_list):\n",
    "        for j, vec2 in enumerate(vec_list):\n",
    "            if i == j or i > j :\n",
    "                continue\n",
    "            elif dim3_distance(vec1,vec2) < 200:\n",
    "                pair_list.append((i,j))\n",
    "    \n",
    "    return pair_list\n",
    "\n",
    "def cam_pos_mean(cam_list):\n",
    "    _cam_pos = np.zeros(3)\n",
    "    for cam in cam_list:\n",
    "        _cam_pos += cam.cam_world_cood\n",
    "    cam_mean = _cam_pos/len(cam_list)\n",
    "    return cam_mean\n",
    "\n",
    "def vec_L2(vec):\n",
    "    return np.sum(vec**2)**(1/2)\n",
    "\n",
    "def cal_angle(cam_pos1, cam_pos2, cam_mean):\n",
    "    vec1 = cam_pos1-cam_mean\n",
    "    vec2 = cam_pos2-cam_mean\n",
    "    cossin = np.dot(vec1, vec2)/(vec_L2(vec1)*vec_L2(vec2))\n",
    "    angle = np.arccos(cossin)\n",
    "    return angle\n",
    "\n",
    "def cal_angle_all(cam_list):\n",
    "    pair_list = []\n",
    "    cam_mean = cam_pos_mean(cam_list)\n",
    "    for i, cam1 in enumerate(cam_list):\n",
    "        for j, cam2 in enumerate(cam_list):\n",
    "            if i == j or i > j:\n",
    "                continue\n",
    "            cam1_pos = cam1.cam_world_cood\n",
    "            cam2_pos = cam2.cam_world_cood\n",
    "            angle = cal_angle(cam1_pos, cam2_pos, cam_mean)\n",
    "            if angle < 5/9*np.pi:\n",
    "                pair_list.append((i,j))\n",
    "    return pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epipole取得\n",
    "\n",
    "def SS_mat(vec3):\n",
    "    vec3 = np.squeeze(vec3)\n",
    "    SS_mat = np.zeros((3, 3))\n",
    "    SS_mat[0,1] = -vec3[2]\n",
    "    SS_mat[0,2] = vec3[1]\n",
    "    SS_mat[1,0] = vec3[2]\n",
    "    SS_mat[1,2] = -vec3[0]\n",
    "    SS_mat[2,0] = -vec3[1]\n",
    "    SS_mat[2,1] = vec3[0]\n",
    "    return SS_mat\n",
    "\n",
    "def FF_mat(A1, A2, Rt1, Rt2):\n",
    "    P1 = np.dot(A1, Rt1[0:3,0:4])\n",
    "    P2 = np.dot(A2, Rt2[0:3,0:4])\n",
    "    cam_pos1 = -np.dot(Rt1[0:3,0:3].T, Rt1[0:3,3])\n",
    "    cam_pos1 = np.array([cam_pos1[0], cam_pos1[1], cam_pos1[2], 1])\n",
    "    epipole2 = np.dot(P2, cam_pos1)\n",
    "    cam_pos2 = -np.dot(Rt2[0:3,0:3].T, Rt2[0:3,3])\n",
    "    cam_pos2 = np.array([cam_pos2[0], cam_pos2[1], cam_pos2[2], 1])\n",
    "    epipole1 = np.dot(P1, cam_pos2)\n",
    "    return epipole1, epipole2, np.dot(SS_mat(epipole2), np.dot(P2, np.linalg.pinv(P1)))\n",
    "\n",
    "#def contour_disassembly(contour_list):\n",
    "#    con_dis = []\n",
    "#    for i in range(len(contour_list)):\n",
    "#        if contour_list[i] == []:\n",
    "#            continue\n",
    "#        which_dis = np.concatenate(contour_list[i])\n",
    "#        con_dis.append(which_dis)\n",
    "#        \n",
    "#    return np.concatenate(con_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポーラ関係\n",
    "def epilines_para(frags, F):\n",
    "    \n",
    "    lines_list = []\n",
    "    for frag in frags:\n",
    "        frag_lines = cv2.computeCorrespondEpilines(frag.reshape(-1,1,2), 1,F) # ndarray(フラグメントの座標数,1,3)\n",
    "        lines_list.append(frag_lines)\n",
    "    \n",
    "    return lines_list\n",
    "\n",
    "#def para2line(parameter):\n",
    "#    \n",
    "#    # 一つのパラメータが渡された時を想定\n",
    "#    line_coode = np.zeros((1920,2), dtype=np.int64)# imgの幅\n",
    "#    para = np.squeeze(parameter)# 3次ベクトル\n",
    "#    for x in range(1920):\n",
    "#        y = int((-para[0]*x - para[2])/para[1])\n",
    "#        line_coode[x,0] = x\n",
    "#        line_coode[x,1] = y\n",
    "#    \n",
    "#    return line_coode\n",
    "\n",
    "#def epiline_cal(frag_paras):\n",
    "#    # 全ての色に対するエピポーラ線の帯の計算\n",
    "#    # lines[色][フラグメント][線][座標]\n",
    "#    lines = []\n",
    "#    for color in frag_paras:\n",
    "#        temp_color = []\n",
    "#        \n",
    "#        for frag in color:\n",
    "#            temp_line = []\n",
    "#\n",
    "#            for point in frag:\n",
    "#                line = para2line(point)\n",
    "#                temp_line.append(line)\n",
    "#\n",
    "#            temp_color.append(temp_line)\n",
    "#        lines.append(temp_color)\n",
    "#        \n",
    "#    return lines\n",
    "\n",
    "#def frags_vs_line(img2_frags, frag_epiline):\n",
    "#    \n",
    "#    # frag_epiline shape(1920, 2)\n",
    "#    surport = np.zeros(len(img2_frags))\n",
    "#    for i in frag_epiline:\n",
    "#        for j, frag in enumerate(img2_frags):\n",
    "#            if i in frag:\n",
    "#                surport[j] += 1\n",
    "#    \n",
    "#    return surport\n",
    "\n",
    "#def pair_frag_idx(img2_frags, frag_epilines):\n",
    "#    surport = np.zeros(len(img2_frags))\n",
    "#    for epi in frag_epilines:\n",
    "#        surport += frags_vs_line(img2_frags, epi)\n",
    "#        \n",
    "#    return surport, np.argmax(surport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(vec3):\n",
    "    return vec3[0]/vec3[2], vec3[1]/vec3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構築\n",
    "def nom_F(F):\n",
    "    return (1/sum(sum(F**2))**(1/2))*F\n",
    "\n",
    "def cover_mat(x1, y1, x2, y2):\n",
    "    return np.array([[x1**2+x2**2, x2*y2, x2, x1*y1, 0, 0, x1, 0, 0],\n",
    "                    [x2*y2, x1**2+y2**2, y2, 0, x1*y1, 0, 0, x1, 0],\n",
    "                    [x2, y2, 1, 0, 0, 0, 0, 0, 0],\n",
    "                    [x1*y1, 0, 0, y1**2+x2**2, x2*y2, x2, y1, 0, 0],\n",
    "                    [0, x1*y1, 0, x2*y2, y1**2+y2**2, y2, 0, y1, 0],\n",
    "                    [0, 0, 0, x2, y2, 1, 0, 0, 0],\n",
    "                    [x1, 0, 0, y1, 0, 0, 1, 0, 0],\n",
    "                    [0, x1, 0, 0, y1, 0, 0, 1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "def min_dist(F, pt1, pt2):# pt1が画像2上の点，pt2が画像1上の点\n",
    "    S0 = 10**10\n",
    "    x1_ori = pt1[0]\n",
    "    y1_ori = pt1[1]\n",
    "    x2_ori = pt2[0]\n",
    "    y2_ori = pt2[1]\n",
    "    \n",
    "    x1 = pt1[0]\n",
    "    y1 = pt1[1]\n",
    "    x2 = pt2[0]\n",
    "    y2 = pt2[1]\n",
    "    \n",
    "    x1_tilda = 0\n",
    "    y1_tilda = 0\n",
    "    x2_tilda = 0\n",
    "    y2_tilda = 0\n",
    "    thita = nom_F(F).flatten()\n",
    "    it = 0\n",
    "    while True:\n",
    "        V_eps = cover_mat(x1, y1, x2, y2)\n",
    "        eps_ast = np.array([x1*x2 + x2*x1_tilda + x2*x2_tilda,\n",
    "                           x1*y2 + y2*x1_tilda + x2*y2_tilda,\n",
    "                           x1 + x1_tilda,\n",
    "                           y1*x2 + x2*y1_tilda + y1 * x2_tilda,\n",
    "                           y1* y2 + y2*y1_tilda + y1*y2_tilda,\n",
    "                           y1 + y1_tilda,\n",
    "                           x2 + x2_tilda,\n",
    "                           y2 + y2_tilda,\n",
    "                           1])\n",
    "        \n",
    "        x1_y1_tilda = np.dot(eps_ast, thita) * np.dot(np.array([[thita[0], thita[1], thita[2]], [thita[3], thita[4], thita[5]]]), np.array([x2, y2, 1])) / np.dot(thita, np.dot(V_eps, thita))\n",
    "        x2_y2_tilda = np.dot(eps_ast, thita) * np.dot(np.array([[thita[0], thita[3], thita[6]], [thita[1], thita[4], thita[7]]]), np.array([x1, y1, 1])) / np.dot(thita, np.dot(V_eps, thita))\n",
    "        \n",
    "        x1_tilda = x1_y1_tilda[0]\n",
    "        y1_tilda = x1_y1_tilda[1]\n",
    "        x2_tilda = x2_y2_tilda[0]\n",
    "        y2_tilda = x2_y2_tilda[1]\n",
    "        \n",
    "        x1 = x1_ori - x1_tilda\n",
    "        y1 = y1_ori - y1_tilda\n",
    "        x2 = x2_ori - x2_tilda\n",
    "        y2 = y2_ori - y2_tilda\n",
    "        \n",
    "        S = x1_tilda**2 + y1_tilda**2 + x2_tilda**2 + y2_tilda**2\n",
    "        \n",
    "        if abs(S0 - S) < 0.00001:\n",
    "            break\n",
    "\n",
    "        elif it == 20:\n",
    "            break\n",
    "\n",
    "        else:\n",
    "            S0 = S\n",
    "            it += 1\n",
    "\n",
    "    return np.array((x1, y1)), np.array((x2, y2))\n",
    "\n",
    "def Ps(P, pt):\n",
    "    a = P[0,0] - pt[0]*P[2,0]\n",
    "    b = P[0,1] - pt[0]*P[2,1]\n",
    "    c = P[0,2] - pt[0]*P[2,2]\n",
    "    d = P[0,3]\n",
    "    e = pt[0]*P[2,3]\n",
    "    f = P[1,0] - pt[1]*P[2,0]\n",
    "    g = P[1,1] - pt[1]*P[2,1]\n",
    "    h = P[1,2] - pt[1]*P[2,2]\n",
    "    i = P[1,3]\n",
    "    j = pt[1]*P[2,3]\n",
    "    return a, b, c, d, e, f, g, h, i, j\n",
    "\n",
    "def tri(P1, P2, pt1, pt2):\n",
    "    #x = sympy.Symbol('x')\n",
    "    #y = sympy.Symbol('y')\n",
    "    #z = sympy.Symbol('z')\n",
    "    a1, b1, c1, d1, e1, f1, g1, h1, i1, j1 = Ps(P1, pt1)\n",
    "    a2, b2, c2, d2, e2, f2, g2, h2, i2, j2 = Ps(P2, pt2)\n",
    "    T = np.array([[a1, b1, c1],\n",
    "                 [f1, g1, h1],\n",
    "                 [a2, b2, c2],\n",
    "                 [f2, g2, h2]])\n",
    "    p = np.array([[d1-e1],\n",
    "                 [i1-j1],\n",
    "                 [d2-e2],\n",
    "                 [i2-j2]])\n",
    "    T_inv = np.linalg.pinv(T)\n",
    "    result_pt = np.dot(T_inv, -p)\n",
    "    return result_pt\n",
    "\n",
    "    #expr1 = a1*x + b1*y + c1*z + d1 - e1\n",
    "    #expr2 = f1*x + g1*y + h1*z + i1 - j1\n",
    "    #expr3 = a2*x + b2*y + c2*z + d2 - e2\n",
    "    #expr4 = f2*x + g2*y + h2*z + i2 - j2\n",
    "    #print(expr1.subs(sympy.solve([expr2, expr3, expr4])))\n",
    "    #result = sympy.solve([expr2, expr3, expr4])\n",
    "    \n",
    "    #return np.array([result[x], result[y], result[z]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_list = [Camera(i) for i in range(24)]\n",
    "for i in range(len(cam_list)):\n",
    "    cam_list[i].img_load()\n",
    "    cam_list[i].contour_extraction()\n",
    "    cam_list[i].para_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポール取得\n",
    "#cam_pairs = cal_angle_all(cam_list)\n",
    "cam_pairs = camera_correspondence(cam_list)\n",
    "epipole_dict = {i:[] for i in range(len(cam_list))}\n",
    "\n",
    "epipole_list = np.zeros((int(len(cam_pairs)*2),2))\n",
    "epipole_list_idx = np.zeros(int(len(cam_pairs)*2))\n",
    "\n",
    "cam_pairs_F = {}\n",
    "for num, i in enumerate(cam_pairs):\n",
    "    epipole1, epipole2, F = FF_mat(cam_list[i[0]].A, cam_list[i[1]].A, cam_list[i[0]].Rt, cam_list[i[1]].Rt)\n",
    "    epipole_dict[i[0]].append(normalization(epipole1))\n",
    "    epipole_dict[i[1]].append(normalization(epipole2))\n",
    "    \n",
    "    epipole_list[int(num*2)] = normalization(epipole1)\n",
    "    epipole_list_idx[int(num*2)] = i[0]\n",
    "    epipole_list[int(num*2)+1] = normalization(epipole2)\n",
    "    epipole_list_idx[int(num*2)+1] = i[1]\n",
    "    \n",
    "    cam_pairs_F[i] = F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エピポールと輪郭上の点を結んだ直線と，x軸のなす角\n",
    "def gene(angles):\n",
    "    # 正規化\n",
    "    B = list(map(lambda y:y-min(angles),angles))\n",
    "    return list(map(lambda y: (y-min(B))/(max(B)-min(B)), B))\n",
    "\n",
    "#def epipole_angle(img_num, epipole_dict):\n",
    "#    cam = cam_list[img_num]\n",
    "#    angle_list = []\n",
    "#    \n",
    "#    for epi in epipole_dict[img_num]:\n",
    "#        epi_angle_list = []\n",
    "#        epi_x = epi[0]\n",
    "#        epi_y = epi[1]\n",
    "#        for contour in cam.contour_list:\n",
    "#            contour_angle_list= []\n",
    "#            for cood in contour:\n",
    "#                x = cood[0][0]\n",
    "#                y = cood[0][1]\n",
    "#                tilt = (y-epi_y)/(x-epi_x)\n",
    "#                angle = np.arctan(tilt)\n",
    "#                contour_angle_list.append(angle)                \n",
    "#            contour_angle_list = gene(contour_angle_list)\n",
    "#            epi_angle_list.append(contour_angle_list)\n",
    "#        angle_list.append(epi_angle_list)\n",
    "#    return angle_list\n",
    "\n",
    "def epipole_angle(img_num, epipole_list, epipole_list_idx):\n",
    "    cam = cam_list[img_num]\n",
    "    angle_list = []\n",
    "    \n",
    "    epipole_img_num_idx = np.where(epipole_list_idx == img_num)\n",
    "    epipole_img_num = epipole_list[epipole_img_num_idx]\n",
    "    for epi in epipole_img_num:\n",
    "        epi_angle_list = []\n",
    "        for contour in cam.contour_list:\n",
    "            pre_tilt = contour - epi\n",
    "            pre_tilt = pre_tilt.reshape([-1,2])\n",
    "            tilt = pre_tilt[:,1]/pre_tilt[:,0]\n",
    "            angle = np.arctan(tilt)\n",
    "            angle = gene(angle)\n",
    "            epi_angle_list.append(angle)\n",
    "        angle_list.append(epi_angle_list)\n",
    "        \n",
    "    return angle_list\n",
    "    \n",
    "#def expand(idx_l, list_length):\n",
    "#    del_list = []\n",
    "#    for i in idx_l:\n",
    "#        if np.isnan(i):\n",
    "#            continue\n",
    "#        if i-2 < 0:\n",
    "#            del_list.append(list_length + i-2)\n",
    "#        else:\n",
    "#            del_list.append(i-2)\n",
    "#        \n",
    "#        if i-1 < 0:\n",
    "#            del_list.append(list_length + i-1)\n",
    "#        else:\n",
    "#           del_list.append(i-1)\n",
    "#        \n",
    "#        del_list.append(i)\n",
    "#        \n",
    "#        if i+1 > list_length-1:\n",
    "#            del_list.append(i+1-list_length)\n",
    "#        else:\n",
    "#            del_list.append(i+1)\n",
    "#        if i+2 > list_length-1:\n",
    "#            del_list.append(i+2-list_length)\n",
    "#        else:\n",
    "#            del_list.append(i+2)\n",
    "#    return sorted(list(set(del_list)))\n",
    "\n",
    "def differential(angles):\n",
    "    # エピポーラ線に平行な接線をもつ点(前後方微分の正負を比べたほうが良い)\n",
    "    del_idx = []\n",
    "    for i in range(len(angles)):\n",
    "        if np.isnan(angles[i]):\n",
    "            continue\n",
    "        if i == len(angles)-1:\n",
    "            if np.sign(angles[i]-angles[i-1]) != np.sign(angles[0]-angles[i]): #or abs(angles[0]-angles[i-1])/2 < 0.001:\n",
    "                del_idx.append(i)\n",
    "        else:\n",
    "            if np.sign(angles[i]-angles[i-1]) != np.sign(angles[i+1]-angles[i]):# or abs(angles[i+1]-angles[i-1])/2 < 0.001:\n",
    "                del_idx.append(i)\n",
    "    #del_idx = expand(del_idx, len(angles))\n",
    "    \n",
    "    return del_idx\n",
    "\n",
    "def marge_del(all_del_list):\n",
    "    marged = []\n",
    "    for j in range(len(all_del_list[0])):\n",
    "        stem = []\n",
    "        for i in range(len(all_del_list)):\n",
    "            stem += all_del_list[i][j]\n",
    "        marged.append(list(set(stem)))\n",
    "    return marged\n",
    "\n",
    "def all_D(angles_list):\n",
    "    # 画像1枚に対して削除リストを作成\n",
    "    all_del_list = []\n",
    "    for epi in angles_list:\n",
    "        epi_del_list = []\n",
    "        for contour in epi:\n",
    "            del_idx = differential(contour)\n",
    "            epi_del_list.append(del_idx)\n",
    "        all_del_list.append(epi_del_list)\n",
    "    marged = marge_del(all_del_list)\n",
    "    return marged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポーラ線との接線で分割\n",
    "def separate(contour, del_idx):\n",
    "    # 一つの輪郭に対し削除リストから削除\n",
    "    start = 0\n",
    "    newArray = []\n",
    "    for d in del_idx:\n",
    "        if contour[start:d] != []:\n",
    "            if contour[start:d].size != 0:\n",
    "                newArray.append(contour[start:d])\n",
    "        start = d+1\n",
    "\n",
    "    if contour[start:].size != 0:\n",
    "        newArray.append(contour[start:])\n",
    "    return newArray\n",
    "\n",
    "def all_sep(con_list, del_list):\n",
    "    n_list = []\n",
    "    for con, del_con in zip(con_list, del_list) :\n",
    "        n_con = separate(con, del_con)\n",
    "        if len(n_con) != 0:\n",
    "            for i in n_con:\n",
    "                n_list.append(i)\n",
    "    return n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frag_max_len(frag_list):\n",
    "    max_len = 0\n",
    "\n",
    "    for i in frag_list:\n",
    "        a = len(i)\n",
    "        if a > max_len:\n",
    "            max_len = a\n",
    "    return max_len\n",
    "\n",
    "def trim_frag_list(frag_list):\n",
    "    max_len = frag_max_len(frag_list)\n",
    "    np_frag_list = np.empty([len(frag_list), 100, 2])\n",
    "    np_frag_list[:,:] = np.nan\n",
    "    for i, frag in enumerate(frag_list):\n",
    "        np_frag_list[i, 0:len(frag),] = np.array(frag)\n",
    "    return np_frag_list\n",
    "\n",
    "def trim_all_frag():\n",
    "    for i in range(len(cam_list)):\n",
    "        _frag_list = cam_list[i].frag_list\n",
    "        np_frag_list = trim_frag_list(_frag_list)\n",
    "        cam_list[i].frag_list = np_frag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# フラグメントのリストを作る\n",
    "for i in range(len(cam_list)):\n",
    "    im_del_list = all_D(epipole_angle(i, epipole_list, epipole_list_idx))# im_del_list[color][contour][del_idx]\n",
    "    newCon = all_sep(cam_list[i].contour_list, im_del_list)# newCon[color][fragment][coordination]\n",
    "    cam_list[i].frag_list = all_fraged(newCon)\n",
    "trim_all_frag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 衝突判定\n",
    "def para2cood_S(para_list):\n",
    "    cood_S = []\n",
    "    for a,b,c in para_list:\n",
    "        if np.isnan(a):\n",
    "            cood_S.append(np.array([np.nan, np.nan]))\n",
    "        else:\n",
    "            cood_S.append(np.array([0, -c/b]))\n",
    "    return cood_S\n",
    "\n",
    "def para2cood_F(para_list):\n",
    "    cood_F = []\n",
    "    for a,b,c in para_list:\n",
    "        if np.isnan(a):\n",
    "            cood_F.append(np.array([np.nan, np.nan]))\n",
    "        else:\n",
    "            cood_F.append(np.array([1920, -(1920*a+c)/b]))# 画像の横の大きさ\n",
    "    return cood_F\n",
    "\n",
    "def all_pa2co(para_list):\n",
    "    epi_cood_S = []\n",
    "    epi_cood_F = []\n",
    "    for frag in para_list:\n",
    "        S_cood = para2cood_S(frag.squeeze())\n",
    "        F_cood = para2cood_F(frag.squeeze())\n",
    "        epi_cood_S.append(S_cood)\n",
    "        epi_cood_F.append(F_cood)\n",
    "    return np.array(epi_cood_S), np.array(epi_cood_F) # epi_cood[frag]\n",
    "\n",
    "def get_frag_cood(frag_list):\n",
    "    cood_S = np.array([frag[0] for frag in frag_list])\n",
    "    cood_F = []\n",
    "    for frag in frag_list:\n",
    "        frag = frag[~np.isnan(frag)]\n",
    "        cood_F.append((frag[-2],frag[-1]))\n",
    "    cood_F = np.array(cood_F)\n",
    "    return cood_S, cood_F # cood_S[frag]\n",
    "\n",
    "def coll_t1_t2(epi_cood_S, epi_cood_F, cood_S, cood_F):\n",
    "    epi_cood_S_bro = np.array([np.broadcast_to(aa, (len(cood_S), 2)) for aa in epi_cood_S])\n",
    "    epi_cood_F_bro = np.array([np.broadcast_to(aa, (len(cood_S), 2)) for aa in epi_cood_F])\n",
    "    #epi_cood_S_bro = np.tile(epi_cood_S, (1,len(cood_S),1)).transpose((1,0,2)) # 遅い\n",
    "    #epi_cood_F_bro = np.tile(epi_cood_F, (1,len(cood_S),1)).transpose((1,0,2))\n",
    "    v = cood_S - epi_cood_S_bro\n",
    "    v2 = cood_F - cood_S\n",
    "    v1 = epi_cood_F_bro - epi_cood_S_bro\n",
    "    t1 = np.cross(v, v2)/np.cross(v1, v2)\n",
    "    t2 = np.cross(v, v1)/np.cross(v1, v2)\n",
    "    return t1, t2\n",
    "\n",
    "def coll_det(t1, t2):\n",
    "    t1_t = np.array((t1 <= 1) & (t1 > 0),dtype=np.int16)\n",
    "    t2_t = np.array((t2 <= 1) & (t2 > 0),dtype=np.int16)\n",
    "    count_c = np.array(t1_t + t2_t == 2, dtype=np.int64)\n",
    "    surport_idx = np.argmax(np.sum(count_c,axis=0))\n",
    "    return surport_idx\n",
    "\n",
    "def make_piar_list(epi_cood_S, epi_cood_F, cood_S, cood_F):\n",
    "    img_list=[]\n",
    "    for epi_frag_S, epi_frag_F in zip(epi_cood_S, epi_cood_F):\n",
    "        t1, t2 = coll_t1_t2(epi_frag_S, epi_frag_F, cood_S, cood_F)\n",
    "        surport_idx = coll_det(t1, t2)\n",
    "        img_list.append(surport_idx)\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:48: RuntimeWarning: divide by zero encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "pair_list = {}\n",
    "for pair in cam_pairs_F:\n",
    "    F = cam_pairs_F[pair]\n",
    "    frags_para12 = epilines_para(cam_list[pair[0]].frag_list, F) # frags_para[色][frag]\n",
    "    frags_para21 = epilines_para(cam_list[pair[1]].frag_list, F.T)\n",
    "    if cam_list[pair[0]].frag_list.size == 0 or cam_list[pair[1]].frag_list.size == 0:\n",
    "        continue\n",
    "    cood_S, cood_F = get_frag_cood(cam_list[pair[1]].frag_list)\n",
    "    epi_cood_S, epi_cood_F = all_pa2co(frags_para12)\n",
    "    \n",
    "    img_list1 = make_piar_list(epi_cood_S, epi_cood_F, cood_S, cood_F)\n",
    "    \n",
    "    cood_S, cood_F = get_frag_cood(cam_list[pair[0]].frag_list)\n",
    "    epi_cood_S, epi_cood_F = all_pa2co(frags_para21)\n",
    "    img_list2 = make_piar_list(epi_cood_S, epi_cood_F, cood_S, cood_F)\n",
    "    \n",
    "    pair_list[((pair[0],pair[1]), \"F\")] = img_list1\n",
    "    pair_list[((pair[0],pair[1]), \"R\")] = img_list2\n",
    "# 直線のパラメータから座標にするとき桁が大きくなりすぎてエラーを吐くことがある（para2cood）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cam_graph(pair_dict, cam_list_length):\n",
    "    keys = list(pair_dict.keys())\n",
    "    keys_graph = []\n",
    "\n",
    "    for main_key in range(cam_list_length):\n",
    "        temp_graph = []\n",
    "\n",
    "        for sub_key in keys:\n",
    "            sub_key_num_1 = sub_key[0][0]\n",
    "            sub_key_num_2 = sub_key[0][1]\n",
    "            if sub_key_num_1 == main_key and sub_key_num_2 not in temp_graph:\n",
    "                temp_graph.append(sub_key_num_2)\n",
    "            elif sub_key_num_2 == main_key and sub_key_num_1 not in temp_graph:\n",
    "                temp_graph.append(sub_key_num_1)\n",
    "        keys_graph.append(temp_graph)\n",
    "    return keys_graph\n",
    "\n",
    "# 固定の深さまでを返す\n",
    "def DFS(graph, start, depth, mark_list):\n",
    "    if start not in mark_list:\n",
    "        mark_list.append(start)\n",
    "    #depth -= 1\n",
    "    if depth == 0:\n",
    "        pass\n",
    "    \n",
    "    elif depth != 0:\n",
    "        depth -= 1\n",
    "        for target in graph[start]:\n",
    "            if target not in mark_list:\n",
    "                mark_list.append(target)\n",
    "                #print(mark_list)\n",
    "                DFS(graph, target, depth, mark_list)\n",
    "    return mark_list\n",
    "\n",
    "def make_key_set(pair_list, cam_list_lenght):\n",
    "    keys_graph = cam_graph(pair_list, cam_list_lenght)\n",
    "    keys = list(pair_list.keys())\n",
    "    set_key_list = []\n",
    "    for idx in range(cam_list_lenght):\n",
    "        \n",
    "        dfs = DFS(keys_graph, idx, 4, [])\n",
    "        sets = key_set_part(dfs, pair_list.keys())\n",
    "        set_key_list.append(sets)\n",
    "    return set_key_list\n",
    "\n",
    "def key_set_part(dfs, keys):\n",
    "    l = []\n",
    "    for i in keys:\n",
    "        for j in dfs:\n",
    "            if j in i[0]:\n",
    "                l.append(i)\n",
    "    return set(l)\n",
    "\n",
    "#def make_key_set(pair_list, cam_list_lenght):\n",
    "#    keys_graph = cam_graph(pair_list, cam_list_lenght)\n",
    "#    keys = list(pair_list.keys())\n",
    "#    set_key_list = []\n",
    "#    for nodes in keys_graph:\n",
    "#        _set_key_list = []\n",
    "#        for node in nodes:\n",
    "#            for key in keys:\n",
    "#                key_num_1 = key[0][0]\n",
    "#                key_num_2 = key[0][1]\n",
    "#                if key_num_1 == node or key_num_2 == node and key not in set_key_list:\n",
    "#                    _set_key_list.append(key)\n",
    "#        set_key_list.append(_set_key_list)\n",
    "#    return set_key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organize_keys(graph_part ,ini, mark_list): \n",
    "    stem = []\n",
    "    for key in graph_part:\n",
    "        if ini == key[0][0] and key[1] == \"F\":\n",
    "            stem.append(key)\n",
    "            mark_list.append(key[0])\n",
    "        elif ini == key[0][1] and key[1] == \"R\":\n",
    "            stem.append(key)\n",
    "            mark_list.append(key[0])\n",
    "            \n",
    "    key_l = []\n",
    "    for i in stem:\n",
    "        if ini == i[0][0]:\n",
    "            idx = i[0][1]\n",
    "        elif ini == i[0][1]:\n",
    "            idx = i[0][0]\n",
    "        l = organize_keys_sub(graph_part, idx, mark_list,[])\n",
    "        _key_l = [i]+l\n",
    "        key_l.append(_key_l)\n",
    "    return key_l\n",
    "\n",
    "def organize_keys_sub(graph_part, idx, mark_list, l):\n",
    "    for key in graph_part:\n",
    "        if idx in key[0]:\n",
    "            \n",
    "            if idx == key[0][0] and key[1] == \"F\" and key[0] not in mark_list:\n",
    "                idx = key[0][1]\n",
    "                mark_list.append(key[0])\n",
    "                l.append(key)\n",
    "                organize_keys_sub(graph_part,idx,mark_list,l)\n",
    "            \n",
    "            elif idx == key[0][1] and key[1] == \"R\" and key[0] not in mark_list:\n",
    "                idx = key[0][0]\n",
    "                mark_list.append(key[0])\n",
    "                l.append(key)\n",
    "                organize_keys_sub(graph_part,idx,mark_list,l)\n",
    "    return l\n",
    "\n",
    "def all_organize_keys(keys):\n",
    "    o_keys=[]\n",
    "    for idx, g_part in enumerate(keys):\n",
    "        o_keys.append(organize_keys(g_part, idx, []))\n",
    "    return o_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_o_key_part(tag_list):\n",
    "    curve_pair_list = []\n",
    "    init_pair = np.array(pair_list[tag_list[0]])\n",
    "    idx_pair = init_pair\n",
    "    curve_pair_list.append(idx_pair)\n",
    "    for i, tag in enumerate(tag_list):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        idx_pair = np.array(pair_list[tag])[idx_pair]\n",
    "        curve_pair_list.append(idx_pair)\n",
    "    return np.array(curve_pair_list)\n",
    "\n",
    "def interpret_o_key_part2(tag_list_list):\n",
    "    c_pair = []\n",
    "    for i in tag_list_list:\n",
    "         c_pair.append(interpret_o_key_part(i))\n",
    "    return np.array(c_pair)\n",
    "\n",
    "def interpret_o_key(tag_list_list_list):\n",
    "    c_pair = []\n",
    "    for i in tag_list_list_list:\n",
    "        c_pair.append(interpret_o_key_part2(i))\n",
    "    return c_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = make_key_set(pair_list, len(cam_list))\n",
    "o_keys = all_organize_keys(s)\n",
    "inted_o_key = interpret_o_key(o_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FR_cheacker(pair, pair_list, cam_list):\n",
    "    F = cam_pairs_F[pair[0]]\n",
    "    if pair[1] == \"F\":\n",
    "        frags_para = epilines_para(cam_list[pair[0][0]].frag_list, F) # frags_para[色][frag]\n",
    "        epi_cood_S, epi_cood_F = all_pa2co(frags_para)\n",
    "        camL_idx = pair[0][1]\n",
    "    elif pair[1] == \"R\":\n",
    "        frags_para = epilines_para(cam_list[pair[0][1]].frag_list, F.T)\n",
    "        epi_cood_S, epi_cood_F = all_pa2co(frags_para)\n",
    "        camL_idx = pair[0][0]\n",
    "    return epi_cood_S, epi_cood_F, camL_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 線と点の衝突判定\n",
    "def PL_coll(pair, pair_list, cam_list):\n",
    "    epi_cood_S, epi_cood_F, camL_idx = FR_cheacker(pair, pair_list, cam_list)\n",
    "    frag_part = cam_list[camL_idx].frag_list\n",
    "    im_list = []\n",
    "    for pair_frag, epi_S_frag, epi_F_frag in zip(pair_list[pair], epi_cood_S, epi_cood_F):\n",
    "        pts = frag_part[pair_frag] # 対応するフラグメント\n",
    "        v1 = epi_F_frag - epi_S_frag\n",
    "        v1_n = (v1[:,0]**2+v1[:,1]**2)**(1/2)\n",
    "        v1_n = np.stack([v1_n, v1_n], axis=1)\n",
    "        v1 = v1/v1_n\n",
    "        v1_bro = np.array([np.broadcast_to(aa, (len(pts), 2)) for aa in v1])\n",
    "        epi_cood_S_bro = np.array([np.broadcast_to(aa, (len(pts), 2)) for aa in epi_S_frag])\n",
    "        v2 = pts - epi_cood_S_bro\n",
    "        v2_n = (v2[:,:,0]**2+v2[:,:,1]**2)**(1/2)\n",
    "        v2_n = np.stack([v2_n, v2_n], axis=2)\n",
    "        v2 = v2/v2_n\n",
    "        con_det = np.cross(v1_bro, v2)\n",
    "        im_list.append(np.where(np.abs(con_det) <= 0.001))\n",
    "    return im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点と線の衝突判定\n",
    "coll_dict = {}\n",
    "for pair in pair_list:\n",
    "    im_list = PL_coll(pair, pair_list, cam_list)\n",
    "    coll_dict[pair] = im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対応点候補から対応点を作る\n",
    "def pt_pair(coll_list):\n",
    "    pool_i = []\n",
    "    pool_j = []\n",
    "    pre_i = None\n",
    "    pre_j = None\n",
    "    pt = 1\n",
    "    for i, j in zip(coll_list[0], coll_list[1]):\n",
    "        if i in pool_i:\n",
    "            if pt == 1:\n",
    "                continue\n",
    "            elif pt == 0:\n",
    "                if j not in pool_j:\n",
    "                    pool_i.pop()\n",
    "                    pool_j.pop()\n",
    "                    pool_i.append(i)\n",
    "                    pool_j.append(j)\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        elif i not in pool_i:\n",
    "            if j in pool_j:\n",
    "                pt = 0\n",
    "            else:\n",
    "                pt = 1\n",
    "            pool_i.append(i)\n",
    "            pool_j.append(j)\n",
    "    return np.array([pool_i, pool_j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 点の一対一対応\n",
    "pair_pt = {}\n",
    "for i in coll_dict:\n",
    "    im_list = []\n",
    "    for frag in coll_dict[i]:\n",
    "        newPair = pt_pair(frag)\n",
    "        im_list.append(newPair)\n",
    "    pair_pt[i] = im_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
       "        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47,\n",
       "        48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n",
       "        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79,\n",
       "        80, 81, 82, 83, 84, 85, 86],\n",
       "       [ 7,  8,  9, 10, 11, 12, 13, 14, 15, 15, 16, 17, 18, 19, 20, 21,\n",
       "        22, 23, 24, 25, 26, 27, 28, 27, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "        37, 38, 39, 40, 41, 42, 43, 44, 44, 45, 46, 47, 48, 49, 50, 51,\n",
       "        67, 53, 54, 55, 56, 79, 57, 78, 77, 61, 76, 74, 75, 73, 52, 72,\n",
       "        71, 70, 69, 66, 68, 65, 64, 63, 62, 60, 59, 58, 56, 82, 85, 84,\n",
       "        81, 80, 87, 86, 83, 81, 83]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_pt[((0, 21), 'F')][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
       "        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
       "       [77, 76, 75, 74, 82, 73, 72, 71, 71, 70, 69, 69, 68, 60, 67, 59,\n",
       "        66, 65, 64, 63, 62, 59, 59, 58, 61, 57, 57, 56, 55, 55, 54, 53,\n",
       "        52, 51, 51, 50, 42, 49, 41, 40, 40, 39, 38, 38, 37]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_pt[((21, 23), 'F')][267]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
       "        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45],\n",
       "       [57, 58, 57, 59, 58, 60, 58, 59, 61, 62, 60, 61, 61, 63, 64, 65,\n",
       "        63, 67, 64, 66, 68, 65, 66, 78, 77, 69, 82, 70, 81, 72, 83, 84,\n",
       "        86, 87, 88, 89, 90, 91, 92, 91, 91, 91, 93, 92, 94, 95]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_pt[((11, 23), 'R')][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,\n",
       "        16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31,\n",
       "        32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46],\n",
       "       [71, 70, 69, 79, 78, 77, 68, 76, 75, 67, 68, 67, 67, 67, 67, 68,\n",
       "        68, 74, 69, 69, 69, 69, 69, 81, 80, 69, 68, 67, 65, 64, 63, 62,\n",
       "        61, 60, 59, 60, 60, 60, 60, 60, 60, 61, 61, 60, 60, 61, 62]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_pt[((11, 19), 'F')][75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前を入れて後のidxを返す関数，対応するidxが無ければ補完する\n",
    "def fb_idx(f_pair_part, b_pair_part):\n",
    "            \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[362 157 299 207  43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\murata\\anaconda3\\envs\\py37cv\\lib\\site-packages\\ipykernel_launcher.py:14: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "init_tag = o_keys[0][0][0]\n",
    "for i, idx in enumerate(inted_o_key[0][0].T):\n",
    "    print(i)\n",
    "    print(idx)\n",
    "    init_pair = pair_pt[init_tag]\n",
    "    pair_0 = init_pair[i]\n",
    "    \n",
    "    sub_pair_part = init_pair[1]\n",
    "    for j in range(len(o_keys[0][0])):\n",
    "        if j == 0:\n",
    "            continue\n",
    "        sub_pair_idx = idx[j-1]\n",
    "        sub_pair = pair_pt[o_keys[0][0][j]][sub_pair_idx]\n",
    "        \n",
    "\n",
    "        \n",
    "        fb_i = fb_idx(sub_pair_part, sub_pair[0])\n",
    "        counterpart = sub_pair[1][fb_i]\n",
    "        sub_pair_part = sub_pair[1]\n",
    "        # init_pairにstackしていく\n",
    "        \n",
    "        \n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 2), 'F'),\n",
       " ((2, 14), 'F'),\n",
       " ((10, 14), 'R'),\n",
       " ((10, 17), 'F'),\n",
       " ((7, 17), 'R')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_keys[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_tag = o_keys[0][0][0]\n",
    "init_pair = pair_pt[init_tag]\n",
    "init_idx = inted_o_key[0][0][0]\n",
    "\n",
    "#for idx in init_idx:\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in init_pair:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untangled_key(o_key):\n",
    "    untangled_list = []\n",
    "    for idx, tag in enumerate(o_key):\n",
    "        if tag[1] == \"F\":\n",
    "            untangled_list.append(tag[0][0])\n",
    "        elif tag[1] == \"R\":\n",
    "            untangled_list.append(tag[0][1])\n",
    "\n",
    "        if idx == len(o_key)-1:\n",
    "            if tag[1] == \"F\":\n",
    "                untangled_list.append(tag[0][1])\n",
    "            elif tag[1] == \"R\":\n",
    "                untangled_list.append(tag[0][0])\n",
    "    return untangled_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 21, 23, 11, 19, 16]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untangled_key(o_keys[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_correspondence_graph(key, correspondence, pair_pt):\n",
    "\n",
    "    pair_1 = pair_pt[key[0]]\n",
    "    pair_2 = pair_pt[key[1]]\n",
    "\n",
    "    pt_corr_list = []\n",
    "\n",
    "    for cam1_frag_idx, cam2_frag_idx in zip(correspondence[:,0], correspondence[:,1]):\n",
    "        cam1_cood_idx, cam2_cood_idx = pair_1[cam1_frag_idx]\n",
    "        pre_cam2_cood_idx, pre_cam3_cood_idx = pair_2[cam2_frag_idx]\n",
    "        pre_sub_idx = 0\n",
    "        cam3_cood_idx = np.zeros(cam2_cood_idx.shape)\n",
    "\n",
    "        for i, sub_cood_idx in enumerate(cam2_cood_idx):\n",
    "            sub_idx = np.where(pre_cam2_cood_idx == sub_cood_idx)\n",
    "            if len(sub_idx[0]) > 1:\n",
    "                idx_diff = 100\n",
    "                for j in sub_idx:\n",
    "                    temp_idx_diff = abs(j-pre_sub_idx)\n",
    "                    if temp_idx_diff < idx_diff:\n",
    "                        sub_idx = j\n",
    "                        idx_diff = temp_idx_diff\n",
    "\n",
    "            elif sub_idx[0].size == 0:\n",
    "                sub_idx = None\n",
    "\n",
    "            else:\n",
    "                sub_idx = sub_idx[0][0]\n",
    "\n",
    "            if sub_idx != None:\n",
    "                cam3_cood_idx[i] = pre_cam3_cood_idx[sub_idx]\n",
    "            else:\n",
    "                cam3_cood_idx[i] = np.nan\n",
    "            pre_sub_idx = sub_idx\n",
    "        pt_corr = np.array([cam1_cood_idx, cam2_cood_idx, cam3_cood_idx])\n",
    "        pt_corr_list.append(pt_corr)\n",
    "    return pt_corr_list\n",
    "\n",
    "def all_pt_corr_graph(key_order, correspondence_list, pair_pt):\n",
    "    main_list = []\n",
    "    for main in range(len(key_order)):\n",
    "        sub_list = []\n",
    "        for sub in range(len(key_order[main])):\n",
    "            key = key_order[main][sub]\n",
    "            correspondence = correspondence_list[main][sub]\n",
    "            pt_corr_list = pt_correspondence_graph(key, correspondence, pair_pt)\n",
    "            sub_list.append(pt_corr_list)\n",
    "        main_list.append(sub_list)\n",
    "    return main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_corr_graph_list = all_pt_corr_graph(key_order, correspondence_list, pair_pt)\n",
    "#pt_corr_graph_list[cam][key_order][curve_num][curves]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FR_frags(dict_tag):\n",
    "    if dict_tag[1] == \"F\":\n",
    "        part = cam_list[dict_tag[0][0]].frag_list\n",
    "        counterpart = cam_list[dict_tag[0][1]].frag_list\n",
    "        return part, counterpart\n",
    "        \n",
    "    elif i[1] == \"R\":\n",
    "        part = cam_list[dict_tag[0][1]].frag_list\n",
    "        counterpart = cam_list[dict_tag[0][0]].frag_list\n",
    "        return part, counterpart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 座標でdictを作る\n",
    "coordinate_dict = {}\n",
    "nan_idx_dict = {}\n",
    "for i in pair_list:\n",
    "    pair_coordinate = []\n",
    "    nan_idx_list = []\n",
    "    part, counterpart = FR_frags(i)\n",
    "    index = 0\n",
    "    for part_frag, pair, pt_idx in zip(part, pair_list[i], pair_pt[i]):\n",
    "        if pt_idx[0].size != 0:\n",
    "            pair_coordinate.append((np.array([part_frag[pt_idx[0]], counterpart[pair][pt_idx[1]]])))\n",
    "        else:\n",
    "            nan_idx_list.append(index)\n",
    "        index += 1\n",
    "    coordinate_dict[i] = pair_coordinate\n",
    "    nan_idx_dict[i] = nan_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FR_check(dict_tag):\n",
    "    if dict_tag[1] == \"F\":\n",
    "        P1 = cam_list[dict_tag[0][0]].P\n",
    "        P2 = cam_list[dict_tag[0][1]].P\n",
    "        F = cam_pairs_F[dict_tag[0]]\n",
    "        return P1, P2, F\n",
    "    elif dict_tag[1] == \"R\":\n",
    "        P1 = cam_list[dict_tag[0][1]].P\n",
    "        P2 = cam_list[dict_tag[0][0]].P\n",
    "        F = cam_pairs_F[dict_tag[0]].T\n",
    "        return P1, P2, F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def connect_points(pts_list):\n",
    "    sep_list = []\n",
    "    root = np.transpose(pts_list[0], (1, 0, 2))\n",
    "    length = len(root)-1\n",
    "    sep_list.append(length)\n",
    "    for i, pt in enumerate(pts_list):\n",
    "        pt = np.transpose(pt, (1, 0, 2))\n",
    "        if i == 0:\n",
    "            continue\n",
    "        root = np.concatenate([root, pt], 0)\n",
    "        length += len(pt)\n",
    "        sep_list.append(length)\n",
    "    return root, sep_list\n",
    "\n",
    "def sep_array(tri_pts, sep_list):\n",
    "    # 一つの輪郭に対し削除リストから削除\n",
    "    start = 0\n",
    "    newArray = []\n",
    "    for d in sep_list:\n",
    "        if tri_pts[start:d].size != 0:\n",
    "            newArray.append(tri_pts[start:d])\n",
    "        start = d\n",
    "\n",
    "    if tri_pts[start:].size != 0:\n",
    "        newArray.append(tri_pts[start:])\n",
    "    return newArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "TDlines = []\n",
    "for i, j in enumerate(coordinate_dict):\n",
    "    \n",
    "    pts = coordinate_dict[j]\n",
    "    P1_ori, P2_ori, F_ori = FR_check(j)\n",
    "    #pt, sep_list = connect_points(pts)\n",
    "    temp_TDlines = []\n",
    "    for pt in pts:\n",
    "        pt = np.transpose(pt, (1, 0, 2))\n",
    "        F = np.broadcast_to(F_ori, (pt.shape[0],3,3))\n",
    "        P1 = np.broadcast_to(P1_ori, (pt.shape[0],3,4))\n",
    "        P2 = np.broadcast_to(P2_ori, (pt.shape[0],3,4))\n",
    "        newcoords= np.array(list(map(min_dist, F, pt[:,1,:], pt[:,0,:])))\n",
    "        tri_pt = np.array(list(map(tri, P1, P2, newcoords[:,1,:], newcoords[:,0,:])))\n",
    "        #pts_array = sep_array(tri_pt, sep_list)\n",
    "        temp_TDlines.append(tri_pt)\n",
    "    TDlines.append(temp_TDlines)\n",
    "    print((i+1)/len(coordinate_dict)*100)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.083333333333333\n",
      "4.166666666666666\n",
      "6.25\n",
      "8.333333333333332\n",
      "10.416666666666668\n",
      "12.5\n",
      "14.583333333333334\n",
      "16.666666666666664\n",
      "18.75\n",
      "20.833333333333336\n",
      "22.916666666666664\n",
      "25.0\n",
      "27.083333333333332\n",
      "29.166666666666668\n",
      "31.25\n",
      "33.33333333333333\n",
      "35.41666666666667\n",
      "37.5\n",
      "39.58333333333333\n",
      "41.66666666666667\n",
      "43.75\n",
      "45.83333333333333\n",
      "47.91666666666667\n",
      "50.0\n",
      "52.083333333333336\n",
      "54.166666666666664\n",
      "56.25\n",
      "58.333333333333336\n",
      "60.416666666666664\n",
      "62.5\n",
      "64.58333333333334\n",
      "66.66666666666666\n",
      "68.75\n",
      "70.83333333333334\n",
      "72.91666666666666\n",
      "75.0\n",
      "77.08333333333334\n",
      "79.16666666666666\n",
      "81.25\n",
      "83.33333333333334\n",
      "85.41666666666666\n",
      "87.5\n",
      "89.58333333333334\n",
      "91.66666666666666\n",
      "93.75\n",
      "95.83333333333334\n",
      "97.91666666666666\n",
      "100.0\n"
     ]
    }
   ],
   "source": [
    "TDlines = {}\n",
    "for i, j in enumerate(coordinate_dict):\n",
    "    \n",
    "    pts = coordinate_dict[j]\n",
    "    P1_ori, P2_ori, F_ori = FR_check(j)\n",
    "    #pt, sep_list = connect_points(pts)\n",
    "    temp_TDlines = []\n",
    "    for pt in pts:\n",
    "        pt = np.transpose(pt, (1, 0, 2))\n",
    "        F = np.broadcast_to(F_ori, (pt.shape[0],3,3))\n",
    "        P1 = np.broadcast_to(P1_ori, (pt.shape[0],3,4))\n",
    "        P2 = np.broadcast_to(P2_ori, (pt.shape[0],3,4))\n",
    "        newcoords= np.array(list(map(min_dist, F, pt[:,1,:], pt[:,0,:])))\n",
    "        tri_pt = np.array(list(map(tri, P1, P2, newcoords[:,1,:], newcoords[:,0,:])))\n",
    "        #pts_array = sep_array(tri_pt, sep_list)\n",
    "        temp_TDlines.append(tri_pt)\n",
    "    TDlines[j] = temp_TDlines\n",
    "    print((i+1)/len(coordinate_dict)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excluded_Parray(ex_tag):\n",
    "    P_dict = {}\n",
    "    for i, cam in enumerate(cam_list):\n",
    "        if i in ex_tag:\n",
    "            continue\n",
    "        P_dict[i] = cam.P\n",
    "    return P_dict\n",
    "\n",
    "def dot_P_frag(P, frag):\n",
    "    repro_frag = []\n",
    "    for pt in frag:\n",
    "        repro_pt = np.dot(P, pt)\n",
    "        repro_pt = np.array(normalization(repro_pt))\n",
    "        repro_frag.append(repro_pt)\n",
    "    return np.array(repro_frag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-efb23f923ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mfrag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfrag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mfrag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfrag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 末尾に1を追加 (X, Y, Z, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mreprojection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot_P_frag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mP_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreprojection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mtemp_reprojection_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mP_tag\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mP_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-c5a2c85473b7>\u001b[0m in \u001b[0;36mdot_P_frag\u001b[1;34m(P, frag)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mrepro_frag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfrag\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mrepro_pt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mrepro_pt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepro_pt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mrepro_frag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepro_pt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reprojection_dict = {}\n",
    "for tag in TDlines:\n",
    "    temp_reprojection_dict = {}\n",
    "    P_dict = excluded_Parray(tag[0])\n",
    "    for P_tag in P_dict:\n",
    "        P = P_dict[P_tag]\n",
    "        P_list = []\n",
    "        for i, frag in enumerate(TDlines[tag]):\n",
    "            frag = frag.reshape((-1,3))\n",
    "            frag = np.concatenate([frag, np.ones(len(frag)).reshape((len(frag), 1))],1) # 末尾に1を追加 (X, Y, Z, 1)\n",
    "            reprojection = dot_P_frag(P, frag)\n",
    "            P_list.append(reprojection)\n",
    "        temp_reprojection_dict[P_tag] = P_list\n",
    "    reprojection_dict[tag] = temp_reprojection_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_contour(contour_list):\n",
    "    con_list = []\n",
    "    A = np.concatenate(contour_list).reshape((-1, 2))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def cal_distance(repro_P, contour_P):\n",
    "    contour_P = connect_contour(contour_P)\n",
    "    distance_list = []\n",
    "    for repro_frag in repro_P:\n",
    "        repro_frag_bro = np.array([np.broadcast_to(aa, (len(contour_P), 2)) for aa in repro_frag])\n",
    "        distance = (np.sum((contour_P - repro_frag_bro)**2,axis=2))**(1/2)\n",
    "        distance_list.append(distance)\n",
    "    return distance_list\n",
    "\n",
    "def distance_check(distance_list):\n",
    "    dist_check_list = []\n",
    "    ac_list = []\n",
    "    for frag in distance_list:\n",
    "        ac = np.array((np.min(frag,axis=1)) < 10,dtype=np.int64) # 条件:10 pixel以内\n",
    "        dist_check_list.append(np.array(sum(ac)/len(ac)))\n",
    "        ac_list.append(ac)\n",
    "    return ac_list, dist_check_list\n",
    "\n",
    "def P_dict_check(repro_dict_taged):\n",
    "    P_list = []\n",
    "    P_ac_list = []\n",
    "    for P_tag in repro_dict_taged:\n",
    "        repro_P = repro_dict_taged[P_tag]\n",
    "        contour_P = cam_list[P_tag].contour_list\n",
    "        distance_list = cal_distance(repro_P, contour_P)\n",
    "        ac_list, dist_check_list = distance_check(distance_list)\n",
    "        P_list.append(dist_check_list)\n",
    "        P_ac_list.append(ac_list)\n",
    "    P_check = np.array(P_list)\n",
    "    return P_ac_list, P_check\n",
    "\n",
    "def P_check_integration(P_check):\n",
    "    temp_list=[]\n",
    "    for img in P_check[:]:\n",
    "        temp = np.array(img > 0.8,dtype=np.int64)# 曲線中の何割が閾値以内か\n",
    "        temp_list.append(temp)\n",
    "    check_list = np.sum(np.array(temp_list),axis=0)\n",
    "    return check_list\n",
    "#########################################\n",
    "def ac_list_integration(P_ac_list):\n",
    "    inter_ac = []\n",
    "    for j in range(len(P_ac_list[0])):\n",
    "        temp_array = np.zeros(len(P_ac_list[0][j]))\n",
    "        for img in P_ac_list:\n",
    "            temp_array += img[j]\n",
    "            inter_ac.append(temp_array)\n",
    "    return inter_ac\n",
    "    \n",
    "def gen_support_dict(reprojection_dicte):\n",
    "    support_dict = {}\n",
    "    for i, tag in enumerate(reprojection_dict):\n",
    "        repro_dict_taged = reprojection_dict[tag]\n",
    "        P_ac_list, P_check = P_dict_check(repro_dict_taged)\n",
    "        check_list = P_check_integration(P_check)\n",
    "        inter_ac = ac_list_integration(P_ac_list)\n",
    "        support_dict[tag] = (check_list, inter_ac)\n",
    "        print((i+1)/len(reprojection_dict)*100)\n",
    "    return support_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "support_dict = gen_support_dict(reprojection_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt_corr_graph_list[cam][key_order][curve_num][sub_cam]\n",
    "#correspondence_list[main_cam][key_order][curve_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_curve_idx = pt_corr_graph_list[0][0][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_order[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx = correspondence_list[0][0][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TD_02_curve = TDlines[((0, 2), 'F')][test_idx[0]]\n",
    "TD_214_curve = TDlines[((2, 14), 'F')][test_idx[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_integrate_02 = TD_02_curve[test_curve_idx[0].astype(np.int16)]\n",
    "pre_integrate_214 = TD_214_curve[test_curve_idx[1].astype(np.int16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_dict[((0,2),\"F\")][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_th = 12 # サポート数\n",
    "curve_fragment = []\n",
    "for tag in TDlines:\n",
    "    #if tag[1] == \"R\":\n",
    "    #    continue\n",
    "    lines_list = TDlines[tag]\n",
    "    support_list, support_ac = support_dict[tag][0], support_dict[tag][1]\n",
    "    for frag, sup, sup_ac in zip(lines_list, support_list, support_ac):\n",
    "        if sup > sup_th:\n",
    "            frag = np.reshape(frag,(-1, 3))\n",
    "            \n",
    "            # if jなら周辺の曲線を引っ張ってきて結合する，結合した曲線のacを-1にする\n",
    "            \n",
    "            frag = np.array([i for i,j in zip(frag, sup_ac >sup_th) if j])\n",
    "            \n",
    "            curve_fragment.append(frag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib notebook\n",
    "\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "fig.patch.set_alpha(0.)\n",
    "# 3DAxesを追加\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 軸ラベルを設定\n",
    "ax.set_xlabel(\"x\", size = 14)\n",
    "ax.set_ylabel(\"z\", size = 14)\n",
    "ax.set_zlabel(\"y\", size = 14)\n",
    "ax.set_box_aspect((1,1,1))\n",
    "\n",
    "def plot_graph():\n",
    "    for frag in curve_fragment:\n",
    "        if frag.size == 0:\n",
    "            continue\n",
    "        #print(frag)\n",
    "        x = frag[:,0]\n",
    "        y = frag[:,1]\n",
    "        z = frag[:,2]\n",
    "        data = [x,y,z]\n",
    "        try:\n",
    "            tck, u= interpolate.splprep(data, k=3)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except TypeError:\n",
    "            pass\n",
    "        new = interpolate.splev(u, tck, der=0)\n",
    "\n",
    "        ax.plot(new[0], new[2], new[1],\"-\")\n",
    "\n",
    "def plt_graph3d(angle):\n",
    "    ax.view_init(azim=angle*5)\n",
    "    \n",
    "# アニメーションを作成\n",
    "ani = FuncAnimation(\n",
    "    fig,\n",
    "    func=plt_graph3d,\n",
    "    frames=72,\n",
    "    init_func=plot_graph,\n",
    "    interval=200\n",
    ")\n",
    "\n",
    "# imagemagickで作成したアニメーションをGIFで書き出す\n",
    "ani.save(\"rolling.gif\", writer=\"pillow\", savefig_kwargs={'transparent': True, 'facecolor': 'none'})\n",
    "ani.save('anim.mp4', writer=\"ffmpeg\", savefig_kwargs={'transparent': True, 'facecolor': 'none'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy import interpolate\n",
    "for i, frag in enumerate(curve_fragment):\n",
    "    if frag.size == 0:\n",
    "        continue\n",
    "    #print(frag)\n",
    "    x = frag[:,0]\n",
    "    y = frag[:,1]\n",
    "    z = frag[:,2]\n",
    "    data = [x,y,z]\n",
    "    try:\n",
    "        tck, u= interpolate.splprep(data, k=3)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    except TypeError:\n",
    "        pass\n",
    "    new = interpolate.splev(u, tck, der=0)\n",
    "    np.savetxt('curve_csv/{}.csv'.format(i), new, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import interpolate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_graph():\n",
    "    for frag in curve_fragment:\n",
    "        if frag.size == 0:\n",
    "            continue\n",
    "        #print(frag)\n",
    "        x = frag[:,0]\n",
    "        y = frag[:,1]\n",
    "        z = frag[:,2]\n",
    "        data = [x,y,z]\n",
    "        \n",
    "        try:\n",
    "            if len(x)<2:\n",
    "                continue\n",
    "            tck, u = interpolate.splprep(data, k=3)\n",
    "            new = interpolate.splev(u, tck, der=0)\n",
    "            ax.plot(new[0], new[2], new[1],\"-\",c=\"#9FC963\")\n",
    "        except ValueError:\n",
    "            pass\n",
    "        except TypeError:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        #ax.plot(x, z, y,\"-\")\n",
    "%matplotlib notebook\n",
    "fig = plt.figure(figsize = (12, 12))\n",
    "fig.patch.set_alpha(0.)\n",
    "# 3DAxesを追加\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 軸ラベルを設定\n",
    "ax.set_xlabel(\"x\", size = 14)\n",
    "ax.set_ylabel(\"z\", size = 14)\n",
    "ax.set_zlabel(\"y\", size = 14)\n",
    "ax.set_box_aspect((1,1,1))\n",
    "#ax.set_xticks(np.arange(-4,4,1))\n",
    "#ax.set_yticks(np.arange(-4,4,1))\n",
    "#ax.set_zticks(np.arange(-2,9,1))\n",
    "\n",
    "plot_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c35615780adbd7a7e120cfa4b92149f373205144cbcd53b49eb71b3aeea55b59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "720px",
    "left": "1550px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
