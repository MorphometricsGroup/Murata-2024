{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pathlib\n",
    "import os\n",
    "from scipy.linalg import null_space\n",
    "import sympy\n",
    "\n",
    "class Camera:\n",
    "    \n",
    "    def __init__(self, val):\n",
    "        self.img_num = val # カメラ番号（int;コンストラクタ）\n",
    "        \n",
    "        f = 8000/3\n",
    "        cx = 1920/2\n",
    "        cy = 1080/2\n",
    "        A = np.zeros((3,3))\n",
    "        A[0,0] = f\n",
    "        A[0,2] = cx\n",
    "        A[1,1] = f\n",
    "        A[1,2] = cy\n",
    "        A[2,2] = 1\n",
    "        \n",
    "        self.A = A # 内部パラメータ(ndarray)\n",
    "\n",
    "    def img_load(self):\n",
    "        folder_path = \"image\"\n",
    "        file_path = os.path.join(folder_path, str(self.img_num) + \".png\")\n",
    "        img = cv2.imread(file_path, 1)# BGRで読み込み\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.flip(img, 1)\n",
    "        self.img = img # 画像(ndarray)\n",
    "        \n",
    "        \n",
    "    def contour_extraction(self):\n",
    "        \n",
    "        color_arr = np.array([[255,0,0],[0,255,0],[0,0,255],\n",
    "                             [255,255,0],[255,0,255],[0,255,255],\n",
    "                             [127,127,127],[127,0,127],[0,127,127]],dtype = np.int16)\n",
    "        masks = np.ones((self.img.shape[0], self.img.shape[1], 9), dtype=np.uint8)\n",
    "        \n",
    "        for i, color in enumerate(color_arr):\n",
    "            lower = np.clip(color, 0, 255)\n",
    "            upper = np.clip(color, 0, 255)\n",
    "            img_mask = cv2.inRange(self.img, lower, upper)\n",
    "            masks[:,:,i] = img_mask\n",
    "        \n",
    "        #self.masks = masks # 色ごとのマスク(nd.array)\n",
    "        \n",
    "        contour_list = []\n",
    "\n",
    "        # 色ごとに輪郭（閉曲線）を抽出\n",
    "        for i in range(masks.shape[2]):\n",
    "            contours, hierarchy = cv2.findContours(masks[:,:,i],cv2.RETR_TREE,cv2.CHAIN_APPROX_NONE)\n",
    "            contour_list.append(contours)\n",
    "        self.contour_list = contour_list # 輪郭のリスト(list,ndarray)\n",
    "\n",
    "        #self.frag_list = contours2fragments(self.contour_list) # フラグメントのリスト(list,ndarray)\n",
    "\n",
    "        \n",
    "    def para_load(self):\n",
    "\n",
    "        folder_path = pathlib.Path(\"view_mat\")\n",
    "        file_path = os.path.join(folder_path, str(self.img_num)+\".csv\")\n",
    "        self.Rt = np.loadtxt(file_path, delimiter=\"\\t\")\n",
    "        self.P = np.dot(self.A, self.Rt[0:3,0:4])\n",
    "        \n",
    "        folder_path = pathlib.Path(\"cam_pos_rot\")\n",
    "        file_path = os.path.join(folder_path, str(self.img_num)+\".csv\")\n",
    "        self.cam_world_cood = np.loadtxt(file_path, delimiter=',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#曲線分割（旧）\n",
    "def split_list(contour_length, max_frag_len=100, min_frag_len=40, min_overrap=10):\n",
    "    \n",
    "    # 輪郭のフラグメントの位置を指定(最小40 pixl)\n",
    "    if contour_length > max_frag_len:\n",
    "        pass\n",
    "    \n",
    "    elif contour_length < 40:\n",
    "        return None\n",
    "    \n",
    "    elif contour_length == 40:\n",
    "        return [0,39]\n",
    "    \n",
    "    else:\n",
    "        max_frag_len = contour_length\n",
    "    \n",
    "    step0 = np.random.randint(min_frag_len, max_frag_len) # 一つ目のフラグメントの長さ（40から100）\n",
    "    frag_list = [[0,step0]]\n",
    "    back = np.random.randint(min_overrap, step0-1) # フラグメントを重ねるために戻す分を決める（最小10 pixl）\n",
    "    next_start = step0 - back\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        # 戻った分(back)より進む\n",
    "        if back+1 > min_frag_len:\n",
    "            step = np.random.randint(back+1, max_frag_len)\n",
    "        else:\n",
    "            step = np.random.randint(min_frag_len, max_frag_len)\n",
    "\n",
    "        full_length = next_start + step\n",
    "        frag = [next_start, full_length]\n",
    "        frag_list.append(frag)\n",
    "        back = np.random.randint(10, step-1)\n",
    "        next_start = full_length - back\n",
    "\n",
    "        # 終了判定\n",
    "        if full_length > contour_length:\n",
    "            break\n",
    "    \n",
    "    # 超過した分戻す（長さはそのまま）\n",
    "    difference = frag_list[-1][1] - (contour_length-1)\n",
    "    frag_list[-1][0] -= difference\n",
    "    frag_list[-1][1] -= difference\n",
    "    \n",
    "    return frag_list\n",
    "\n",
    "\n",
    "def contours_split(contour):\n",
    "    \n",
    "    #contour.shape == (N, 2)\n",
    "    contour_length = contour.shape[0]\n",
    "    sp_list = split_list(contour_length)\n",
    "    \n",
    "    if sp_list == None:\n",
    "        return None\n",
    "    \n",
    "    frag_list = []\n",
    "    \n",
    "    # 位置のリスト通りにスライス\n",
    "    for sp in sp_list:\n",
    "\n",
    "        frag_list.append(contour[sp[0]:sp[1],:])\n",
    "        \n",
    "    return frag_list\n",
    "\n",
    "\n",
    "def contours2fragments(contours_list):\n",
    "    \n",
    "    # 輪郭のリストからフラグメントのリストを得る\n",
    "    frags_list = []\n",
    "\n",
    "    for i in contours_list:\n",
    "        temp_list = []\n",
    "        frags = []\n",
    "        for j in i:\n",
    "            temp_frags = contours_split(j.squeeze())\n",
    "            \n",
    "            if temp_frags != None:\n",
    "                frags += temp_frags\n",
    "\n",
    "        if frags != []:\n",
    "            frags_list.append(frags)\n",
    "    \n",
    "    return frags_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera対応\n",
    "def dim3_distance(vec1, vec2):\n",
    "    return sum((vec1-vec2)**2)\n",
    "\n",
    "def camera_correspondence(cam_list):\n",
    "    vec_list = []\n",
    "    for i,cam in enumerate(cam_list):\n",
    "        cam_list[i].para_load()\n",
    "        vec_list.append(cam_list[i].cam_world_cood)\n",
    "\n",
    "    pair_list = []\n",
    "    for i, vec1 in enumerate(vec_list):\n",
    "        for j, vec2 in enumerate(vec_list):\n",
    "            if i == j or i > j :\n",
    "                continue\n",
    "            elif dim3_distance(vec1,vec2) < 2:\n",
    "                pair_list.append((i,j))\n",
    "    \n",
    "    return pair_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epipole取得\n",
    "\n",
    "def SS_mat(vec3):\n",
    "    vec3 = np.squeeze(vec3)\n",
    "    SS_mat = np.zeros((3, 3))\n",
    "    SS_mat[0,1] = -vec3[2]\n",
    "    SS_mat[0,2] = vec3[1]\n",
    "    SS_mat[1,0] = vec3[2]\n",
    "    SS_mat[1,2] = -vec3[0]\n",
    "    SS_mat[2,0] = -vec3[1]\n",
    "    SS_mat[2,1] = vec3[0]\n",
    "    return SS_mat\n",
    "\n",
    "def FF_mat(A1, A2, Rt1, Rt2):\n",
    "    P1 = np.dot(A1, Rt1[0:3,0:4])\n",
    "    P2 = np.dot(A2, Rt2[0:3,0:4])\n",
    "    cam_pos = -np.dot(Rt1[0:3,0:3].T, Rt1[0:3,3])\n",
    "    cam_pos = np.array([cam_pos[0], cam_pos[1], cam_pos[2], 1])\n",
    "    epipole2 = np.dot(P2, cam_pos)\n",
    "    cam_pos = -np.dot(Rt2[0:3,0:3].T, Rt2[0:3,3])\n",
    "    cam_pos = np.array([cam_pos[0], cam_pos[1], cam_pos[2], 1])\n",
    "    epipole1 = np.dot(P1, cam_pos)\n",
    "    return epipole1, epipole2, np.dot(SS_mat(epipole2), np.dot(P2, np.linalg.pinv(P1)))\n",
    "\n",
    "def contour_disassembly(contour_list):\n",
    "    con_dis = []\n",
    "    for i in range(len(contour_list)):\n",
    "        if contour_list[i] == []:\n",
    "            continue\n",
    "        which_dis = np.concatenate(contour_list[i])\n",
    "        con_dis.append(which_dis)\n",
    "        \n",
    "    return np.concatenate(con_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポーラ関係，サポートに使用\n",
    "def epilines_para(frags, F):\n",
    "    \n",
    "    lines2_list = []\n",
    "    for color in frags:\n",
    "        temp_color_list = []\n",
    "        for frag in color:\n",
    "            frag_lines = cv2.computeCorrespondEpilines(frag.reshape(-1,1,2), 1,F) # ndarray(フラグメントの座標数,1,3)\n",
    "            temp_color_list.append(frag_lines)\n",
    "\n",
    "        lines2_list.append(temp_color_list)\n",
    "    \n",
    "    return lines2_list\n",
    "\n",
    "\n",
    "def para2line(parameter):\n",
    "    \n",
    "    #一つのパラメータが渡された時を想定\n",
    "    line_coode = np.zeros((1920,2), dtype=np.int64)\n",
    "    para = np.squeeze(parameter)# 3次ベクトル\n",
    "    for x in range(1920):\n",
    "        y = int((-para[0]*x - para[2])/para[1])\n",
    "        line_coode[x,0] = x\n",
    "        line_coode[x,1] = y\n",
    "    \n",
    "    return line_coode\n",
    "\n",
    "\n",
    "def epiline_cal(frag_paras):\n",
    "    #全ての色に対するエピポーラ線の帯の計算\n",
    "    #lines[色][フラグメント][線][座標]\n",
    "    lines = []\n",
    "    for color in frag_paras:\n",
    "        temp_color = []\n",
    "        \n",
    "        for frag in color:\n",
    "            temp_line = []\n",
    "\n",
    "            for point in frag:\n",
    "                line = para2line(point)\n",
    "                temp_line.append(line)\n",
    "\n",
    "            temp_color.append(temp_line)\n",
    "        lines.append(temp_color)\n",
    "        \n",
    "    return lines2_list\n",
    "\n",
    "\n",
    "def frag_vs_line(img2_frags, frag_epiline):\n",
    "    \n",
    "    # frag_epiline shape(1920, 2)\n",
    "    surport = np.zeros(len(img2_frags))\n",
    "    for i in frag_epiline:\n",
    "        for j, frag in enumerate(img2_frags):\n",
    "            if i in frag:\n",
    "                surport[j] += 1\n",
    "    \n",
    "    return surport\n",
    "\n",
    "\n",
    "def pair_frag_idx(img2_frags, frag_epilines):\n",
    "    surport = np.zeros(len(img2_frags))\n",
    "    for epi in frag_epilines:\n",
    "        surport += frag_vs_line(img2_frags, epi)\n",
    "        \n",
    "    return np.argmax(surport)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(vec3):\n",
    "    return vec3[0]/vec3[2], vec3[1]/vec3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構築\n",
    "def nom_F(F):\n",
    "    return (1/sum(sum(F**2))**(1/2))*F\n",
    "\n",
    "def cover_mat(x1, y1, x2, y2):\n",
    "    return np.array([[x1**2+x2**2, x2*y2, x2, x1*y1, 0, 0, x1, 0, 0],\n",
    "                    [x2*y2, x1**2+y2**2, y2, 0, x1*y1, 0, 0, x1, 0],\n",
    "                    [x2, y2, 1, 0, 0, 0, 0, 0, 0],\n",
    "                    [x1*y1, 0, 0, y1**2+x2**2, x2*y2, x2, y1, 0, 0],\n",
    "                    [0, x1*y1, 0, x2*y2, y1**2+y2**2, y2, 0, y1, 0],\n",
    "                    [0, 0, 0, x2, y2, 1, 0, 0, 0],\n",
    "                    [x1, 0, 0, y1, 0, 0, 1, 0, 0],\n",
    "                    [0, x1, 0, 0, y1, 0, 0, 1, 0],\n",
    "                    [0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
    "\n",
    "def min_dist(F, pt1, pt2):# pt1が画像2上の点，pt2が画像1上の点\n",
    "    S0 = 10**10\n",
    "    x1_ori = pt1[0]\n",
    "    y1_ori = pt1[1]\n",
    "    x2_ori = pt2[0]\n",
    "    y2_ori = pt2[1]\n",
    "    \n",
    "    x1 = pt1[0]\n",
    "    y1 = pt1[1]\n",
    "    x2 = pt2[0]\n",
    "    y2 = pt2[1]\n",
    "    \n",
    "    x1_tilda = 0\n",
    "    y1_tilda = 0\n",
    "    x2_tilda = 0\n",
    "    y2_tilda = 0\n",
    "    thita = nom_F(F).flatten()\n",
    "\n",
    "    while True:\n",
    "        V_eps = cover_mat(x1, y1, x2, y2)\n",
    "        eps_ast = np.array([x1*x2 + x2*x1_tilda + x2*x2_tilda,\n",
    "                           x1*y2 + y2*x1_tilda + x2*y2_tilda,\n",
    "                           x1 + x1_tilda,\n",
    "                           y1*x2 + x2*y1_tilda + y1 * x2_tilda,\n",
    "                           y1* y2 + y2*y1_tilda + y1*y2_tilda,\n",
    "                           y1 + y1_tilda,\n",
    "                           x2 + x2_tilda,\n",
    "                           y2 + y2_tilda,\n",
    "                           1])\n",
    "        \n",
    "        x1_y1_tilda = np.dot(eps_ast, thita) * np.dot(np.array([[thita[0], thita[1], thita[2]], [thita[3], thita[4], thita[5]]]), np.array([x2, y2, 1])) / np.dot(thita, np.dot(V_eps, thita))\n",
    "        x2_y2_tilda = np.dot(eps_ast, thita) * np.dot(np.array([[thita[0], thita[3], thita[6]], [thita[1], thita[4], thita[7]]]), np.array([x1, y1, 1])) / np.dot(thita, np.dot(V_eps, thita))\n",
    "        \n",
    "        x1_tilda = x1_y1_tilda[0]\n",
    "        y1_tilda = x1_y1_tilda[1]\n",
    "        x2_tilda = x2_y2_tilda[0]\n",
    "        y2_tilda = x2_y2_tilda[1]\n",
    "        \n",
    "        x1 = x1_ori - x1_tilda\n",
    "        y1 = y1_ori - y1_tilda\n",
    "        x2 = x2_ori - x2_tilda\n",
    "        y2 = y2_ori - y2_tilda\n",
    "        \n",
    "        S = x1_tilda**2 + y1_tilda**2 + x2_tilda**2 + y2_tilda**2\n",
    "        \n",
    "        if S0 - S == 0:\n",
    "            break\n",
    "        else:\n",
    "            S0 = S\n",
    "\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def tri(P1, P2, pt1, pt2):\n",
    "    x = sympy.Symbol('x')\n",
    "    y = sympy.Symbol('y')\n",
    "    z = sympy.Symbol('z')\n",
    "    a1, b1, c1, d1, e1, f1, g1, h1, i1, j1 = Ps(P1, pt1)\n",
    "    a2, b2, c2, d2, e2, f2, g2, h2, i2, j2 = Ps(P2, pt2)\n",
    "    \n",
    "    expr1 = a1*x + b1*y + c1*z + d1 - e1\n",
    "    expr2 = f1*x + g1*y + h1*z + i1 - j1\n",
    "    expr3 = a2*x + b2*y + c2*z + d2 - e2\n",
    "    expr4 = f2*x + g2*y + h2*z + i2 - j2\n",
    "    print(expr1.subs(sympy.solve([expr2, expr3, expr4])))\n",
    "    \n",
    "    return sympy.solve([expr2, expr3, expr4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_list = [Camera(i) for i in range(24)]\n",
    "cam_pairs = camera_correspondence(cam_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エピポール取得\n",
    "cam_pairs = camera_correspondence(cam_list)\n",
    "\n",
    "epipole_dict = {i:[] for i in range(24)}\n",
    "for i in cam_pairs:\n",
    "    cam1 = cam_list[i[0]]\n",
    "    cam2 = cam_list[i[1]]\n",
    "    cam1.img_load()\n",
    "    cam2.img_load()\n",
    "    cam1.contour_extraction()\n",
    "    cam2.contour_extraction()\n",
    "    cam1.para_load()\n",
    "    cam2.para_load()\n",
    "    \n",
    "    epipole1, epipole2, _ = FF_mat(cam1.A, cam2.A, cam1.Rt, cam2.Rt)\n",
    "    epipole_dict[i[0]].append(normalization(epipole1))\n",
    "    epipole_dict[i[1]].append(normalization(epipole2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エピポールと輪郭上の点を結んだ直線と，x軸のなす角\n",
    "def epipole_angle(img_num, epipole_dict):\n",
    "    cam = cam_list[img_num]\n",
    "    cam.img_load()\n",
    "    cam.contour_extraction()\n",
    "    epi_x = epipole_dict[img_num][0][0]\n",
    "    epi_y = epipole_dict[img_num][0][1]\n",
    "    angle_list = []\n",
    "    \n",
    "    for color in cam.contour_list:\n",
    "        color_angle_list = []\n",
    "        for contour in color:\n",
    "            contour_angle_list= []\n",
    "            for cood in contour:\n",
    "                x = cood[0][0]\n",
    "                y = cood[0][1]\n",
    "                tilt = (y-epi_y)/(x-epi_x)\n",
    "                angle = np.arctan(tilt)\n",
    "                contour_angle_list.append(angle)\n",
    "            color_angle_list.append(contour_angle_list)\n",
    "        angle_list.append(color_angle_list)\n",
    "    return angle_list\n",
    "\n",
    "# エピポーラ線に平行な接線をもつ点\n",
    "def differential(angles):\n",
    "    \n",
    "    del_idx = []\n",
    "    for i in range(len(angles)):\n",
    "        if i == 0 or i == len(angles)-1:\n",
    "            continue\n",
    "        else:\n",
    "            if abs(angles[i+1]-angles[i-1])/2*10**5 < 2.5:\n",
    "                if i+2 == len(angles):\n",
    "                    del_idx.append(0)\n",
    "                else:\n",
    "                    del_idx.append(i+2)\n",
    "                    \n",
    "                del_idx.append(i+1)\n",
    "                del_idx.append(i)\n",
    "                del_idx.append(i-1)\n",
    "                \n",
    "                if i-2 < 0:\n",
    "                    del_idx.append(len(angles)-1)\n",
    "                else:\n",
    "                    del_idx.append(i-2)\n",
    "    \n",
    "    angles = np.roll(np.array(angles),int(len(angles)/2))\n",
    "    \n",
    "    for i in range(len(angles)):\n",
    "        if i == 0 or i == len(angles)-1:\n",
    "            continue\n",
    "        else:\n",
    "            if abs(angles[i+1]-angles[i-1])/2*10**5 < 2.5:\n",
    "                if i+2 >= int(len(angles)/2):\n",
    "                    del_idx.append(i+2-int(len(angles)/2))\n",
    "                else:\n",
    "                    if len(angles)-1+i+2-int(len(angles)/2) == len(angles):\n",
    "                        del_idx.append(int(len(angles)/2))\n",
    "                    else:\n",
    "                        del_idx.append(len(angles)-1+i+2-int(len(angles)/2))\n",
    "                if i+1 >= int(len(angles)/2):\n",
    "                    del_idx.append(i+1-int(len(angles)/2))\n",
    "                else:\n",
    "                    del_idx.append(len(angles)-1+i+1-int(len(angles)/2))\n",
    "                \n",
    "                if i >= int(len(angles)/2):\n",
    "                    del_idx.append(i-int(len(angles)/2))\n",
    "                else:\n",
    "                    del_idx.append(len(angles)-1+i-int(len(angles)/2))\n",
    "                    \n",
    "                if i-1 >= int(len(angles)/2):\n",
    "                    del_idx.append(i-1-int(len(angles)/2))\n",
    "                else:\n",
    "                    del_idx.append(len(angles)-1+i-1-int(len(angles)/2))\n",
    "                    \n",
    "                if i-2 >= int(len(angles)/2):\n",
    "                    del_idx.append(i+2-int(len(angles)/2))\n",
    "                else:\n",
    "                    del_idx.append(len(angles)-1+i-2-int(len(angles)/2))\n",
    "                \n",
    "                \n",
    "    return list(set(del_idx))\n",
    "\n",
    "def all_D(angles_list):\n",
    "    all_del_list = []\n",
    "    for color in angles_list:\n",
    "        color_del_list = []\n",
    "        for contour in color:\n",
    "            #if len(contour)<40:\n",
    "            #    continue\n",
    "            del_idx = differential(contour)\n",
    "            color_del_list.append(del_idx)\n",
    "        all_del_list.append(color_del_list)\n",
    "    return all_del_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(all_D(epipole_angle(0, epipole_dict)), cam_list[0].contour_list):\n",
    "    print(len(i)==len(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = cam_pairs[0]\n",
    "print(i)\n",
    "\n",
    "cam1 = cam_list[i[0]]\n",
    "cam2 = cam_list[i[1]]\n",
    "cam1.img_load()\n",
    "cam2.img_load()\n",
    "cam1.contour_extraction()\n",
    "cam2.contour_extraction()\n",
    "cam1.para_load()\n",
    "cam2.para_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
